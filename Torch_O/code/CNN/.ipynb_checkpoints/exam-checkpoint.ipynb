{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec69a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "random.seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.cuda.manual_seed_all(random_seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd414149",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([[0.9408, 0.1332],\n",
    "        [0.9346, 0.5936],\n",
    "        [0.8694, 0.5677],\n",
    "        [0.7411, 0.4294]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec37d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "#         setattr(self, '123123', nn.Sequential())\n",
    "        self.layers=nn.Sequential(nn.Linear(2,4),nn.Sequential(nn.Linear(4,2),nn.Linear(4,2)))\n",
    "#         self.tmp = nn.Linear(2,4)\n",
    "#         self.tmp1 = nn.Linear(4,2)\n",
    "#         self.tmp2 = nn.Linear(4,2)\n",
    "#         method = getattr(self, self.name)\n",
    "#         a=getattr(self, '123123')\n",
    "#         a.add_module('456',nn.Linear(4,2))\n",
    "    def forward(self, x):\n",
    "        out = self.layers(nn.Linear(2,4)(x),nn.Sequential(nn.Linear(4,2),nn.Linear(4,2)))\n",
    "#         out = [self.tmp1(self.tmp(x)),self.tmp2(self.tmp(x))]\n",
    "        out = torch.cat(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7226382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed= 1234\n",
    "torch.manual_seed(seed)\n",
    "a=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "967788c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight\n",
      "layers.0.bias\n",
      "layers.1.0.weight\n",
      "layers.1.0.bias\n",
      "layers.1.1.weight\n",
      "layers.1.1.bias\n"
     ]
    }
   ],
   "source": [
    "for i in a.state_dict():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "038c97a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x2 and 4x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12168/1656867319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12168/2348056442.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#         a.add_module('456',nn.Linear(4,2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m#         out = [self.tmp1(self.tmp(x)),self.tmp2(self.tmp(x))]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x2 and 4x2)"
     ]
    }
   ],
   "source": [
    "# test1\n",
    "a.forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0036941",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['parallel',\n",
    "            ['conv',{'ksize':1, 'chn':64}],\n",
    "         \n",
    "            ['serial',\n",
    "                ['conv',{'ksize':1,'chn':48}],\n",
    "                ['conv',{'ksize':5, 'chn':64}]],\n",
    "         \n",
    "            ['serial',\n",
    "                ['conv',{'ksize':1,'chn':64}],\n",
    "                 ['conv',{'ksize':3,'chn':96}],\n",
    "                 ['conv',{'ksize':3,'chn':96}]],\n",
    "         \n",
    "            ['serial',\n",
    "                ['avg',{'ksize':3,'stride':1}],\n",
    "                ['conv',{'ksize':1,'chn':'#chn'}]]\n",
    "        \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c245a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class modules(nn.Module):\n",
    "#     def __init__(self, layers):\n",
    "        \n",
    "#         super(modules, self).__init__()\n",
    "        \n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             *layers\n",
    "#                                     )\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         out = self.layer1(x)\n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "373151d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mk_modules(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(mk_modules, self).__init__()\n",
    "        \n",
    "        self.name, layer = layers\n",
    "\n",
    "        setattr(self, self.name, nn.Sequential(*layer))\n",
    "        \n",
    "#         print(layer)\n",
    "    def forward(self, x ):\n",
    "        \n",
    "        method = getattr(self, self.name)\n",
    "        out = method(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f25696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, tmp):\n",
    "#         tmp=tmp\n",
    "#         print(type(tmp),len(tmp))\n",
    "        super(Net, self).__init__()\n",
    "#         print(tmp.__class__.__name__)\n",
    "#         tmp.__class__.\n",
    "        c=[]\n",
    "        for i in tmp:\n",
    "            for j in i.children():\n",
    "                \n",
    "#                 print(j)\n",
    "                c.append(j)\n",
    "#                 break\n",
    "#             self.name , module = i\n",
    "        self.layer1 = nn.Sequential(\n",
    "            *c\n",
    "                            )\n",
    "        print(self.layer1[0])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out1 = self.layer1[0](x)\n",
    "        out2 = self.layer1[1](x)\n",
    "        out3 = self.layer1[2](x)\n",
    "        out=torch.cat([out1,out2,out3],dim=0)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54f131b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, a):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            *a\n",
    "                            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = []\n",
    "        for i in self.layer1.children():\n",
    "            out.append(i(x))\n",
    "#         out1 = self.layer1\n",
    "        cat=torch.cat(out,dim=0)\n",
    "        \n",
    "        return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a57e2248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "inchannels = 3\n",
    "# for i in range(2):\n",
    "layer = ('_1x1',[nn.Conv2d(in_channels=inchannels,out_channels=24,kernel_size=1)])\n",
    "# tmptmp=mk_modules(layer)\n",
    "tmp.append(layer)\n",
    "# tmp.append(mk_modules(layer))\n",
    "\n",
    "layer = ('_5x5',[nn.Conv2d(in_channels=inchannels,out_channels=16,kernel_size=1),\n",
    "               nn.Conv2d(in_channels=16,out_channels=24,kernel_size=5,padding=2)])\n",
    "tmp.append(layer)\n",
    "tmp.append(mk_modules(layer))\n",
    "\n",
    "layer = ('_3x3',[nn.Conv2d(in_channels=inchannels,out_channels=16,kernel_size=1),\n",
    "               nn.Conv2d(in_channels=16,out_channels=24,kernel_size=3,padding=1)])\n",
    "tmp.append(layer)\n",
    "# tmp.append(mk_modules(layer))\n",
    "# print(tmp)\n",
    "\n",
    "# layer = ('seq',[nn.Conv2d(in_channels=inchannels,out_channels=16,kernel_size=1),\n",
    "#                nn.Conv2d(in_channels=16,out_channels=24,kernel_size=3,padding=1)])\n",
    "# tmp.append(mk_modules(layer))\n",
    "\n",
    "# x=mk_modules(layer)\n",
    "\n",
    "\n",
    "a=Net(tmp)\n",
    "x=torch.rand([10,3,299,299])\n",
    "z=a(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e97b51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): mk_modules(\n",
      "    (_1x1): Sequential(\n",
      "      (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (1): mk_modules(\n",
      "    (_5x5): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (2): mk_modules(\n",
      "    (_3x3): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in a.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e18568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mk_modules(\n",
       "   (_1x1): Sequential(\n",
       "     (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "   )\n",
       " ),\n",
       " mk_modules(\n",
       "   (_5x5): Sequential(\n",
       "     (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "     (1): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   )\n",
       " ),\n",
       " mk_modules(\n",
       "   (_3x3): Sequential(\n",
       "     (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "     (1): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e120b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.layer123 = nn.Sequential()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output= []\n",
    "        for i in self.layer123:\n",
    "            output.append(i(x))\n",
    "            \n",
    "        cat=torch.cat(output,dim=1)\n",
    "        \n",
    "        return cat\n",
    "            \n",
    "# model = nn.Sequential()\n",
    "a= model()\n",
    "a.layer123.add_module('conv0', tmp[0])\n",
    "a.layer123.add_module('norm0', tmp[1])\n",
    "a.layer123.add_module('norm1', tmp[2])\n",
    "\n",
    "# for i in model.children():\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f9d6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,layer):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer3 =nn.Sequential(*layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out33 = self.layer3(x)\n",
    "        \n",
    "        return out33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b5c7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand([10,3,299,299])\n",
    "b=Net([a])\n",
    "z=b(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7410d617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 72, 299, 299])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "814cb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "random.seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.cuda.manual_seed_all(random_seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "321bd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([[0.9408, 0.1332],\n",
    "        [0.9346, 0.5936],\n",
    "        [0.8694, 0.5677],\n",
    "        [0.7411, 0.4294]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a30e5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        setattr(self, '123123', nn.Sequential())\n",
    "#         self.layers=nn.Sequential()\n",
    "        self.tmp = nn.Linear(2,4)\n",
    "        self.tmp1 = nn.Linear(4,2)\n",
    "        self.tmp2 = nn.Linear(4,2)\n",
    "#         method = getattr(self, self.name)\n",
    "        a=getattr(self, '123123')\n",
    "        a.add_module('456',nn.Linear(4,2))\n",
    "    def forward(self, x):\n",
    "#         out = self.tmp(x)\n",
    "        out = [self.tmp1(self.tmp(x)),self.tmp2(self.tmp(x))]\n",
    "        out = torch.cat(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f75b98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "#         setattr(self, '123123', nn.Sequential())\n",
    "        self.layers=nn.Sequential(nn.Linear(2,4))\n",
    "        self.layers.add_module(nn.Sequential(nn.Linear(4,2),nn.Linear(4,2)))\n",
    "#         self.tmp = nn.Linear(2,4)\n",
    "#         self.tmp1 = nn.Linear(4,2)\n",
    "#         self.tmp2 = nn.Linear(4,2)\n",
    "#         method = getattr(self, self.name)\n",
    "#         a=getattr(self, '123123')\n",
    "#         a.add_module('456',nn.Linear(4,2))\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "#         out = [self.tmp1(self.tmp(x)),self.tmp2(self.tmp(x))]\n",
    "        out = torch.cat(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e3edca22",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11968/4077561643.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1234\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11968/2542507443.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#         setattr(self, '123123', nn.Sequential())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#         self.tmp = nn.Linear(2,4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         self.tmp1 = nn.Linear(4,2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_item_by_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36madd_module\u001b[1;34m(self, name, module)\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m             raise TypeError(\"{} is not a Module subclass\".format(\n\u001b[1;32m--> 373\u001b[1;33m                 torch.typename(module)))\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             raise TypeError(\"module name should be a string. Got {}\".format(\n",
      "\u001b[1;31mTypeError\u001b[0m: list is not a Module subclass"
     ]
    }
   ],
   "source": [
    "seed= 1234\n",
    "torch.manual_seed(seed)\n",
    "a=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f157489f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "  )\n",
       "  (layers1): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=4, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7b4e15da",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'tmp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11968/3154328288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m-> 1131\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Net' object has no attribute 'tmp'"
     ]
    }
   ],
   "source": [
    "a.tmp.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee8eedce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2560, -0.2805],\n",
       "        [-0.3323, -0.3199],\n",
       "        [-0.3104, -0.3247],\n",
       "        [-0.2524, -0.3269],\n",
       "        [-0.0037,  0.0038],\n",
       "        [ 0.0587,  0.0528],\n",
       "        [ 0.0764,  0.0446],\n",
       "        [ 0.0998,  0.0191]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test1\n",
    "a.forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ef2a3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2560, -0.2805],\n",
       "        [-0.3323, -0.3199],\n",
       "        [-0.3104, -0.3247],\n",
       "        [-0.2524, -0.3269],\n",
       "        [-0.0037,  0.0038],\n",
       "        [ 0.0587,  0.0528],\n",
       "        [ 0.0764,  0.0446],\n",
       "        [ 0.0998,  0.0191]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5bfdceb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x2 and 4x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11968/271456035.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11968/3589236675.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         out = [self.tmp1(self.tmp(x)),self.tmp2(self.tmp(x))]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x2 and 4x2)"
     ]
    }
   ],
   "source": [
    "a.forward(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6274a7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('namename',\n",
       "  Sequential(\n",
       "    (conv1): Conv2d(3, 2, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (conv): Conv2d(3, 2, kernel_size=(2, 2), stride=(1, 1))\n",
       "  ))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.layers.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9916178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(np.array([2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0354a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(torch.rand([3,5]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45b4813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.prod(torch.tensor([2,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3a7700af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mk_modules(\n",
       "  (_1x1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.layer1._modules['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8282cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__func__', '__ge__', '__get__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__func__', '__ge__', '__get__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__func__', '__ge__', '__get__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
     ]
    }
   ],
   "source": [
    "a.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1b0c779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'd'\n",
    "d='f'\n",
    "s=globals()['{}'.format(name)]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4356bdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "      (1): Conv2d(3, 6, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Linear(in_features=6, out_features=3, bias=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "      (1): Conv2d(3, 6, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (2): Linear(in_features=6, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03bbf72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "for i in layers:\n",
    "    if isinstance(i, nn.Linear):\n",
    "        print(i.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab17b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(layers, nn.Linear):\n",
    "    print(layers.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b60b2ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_7120/953631979.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\oh\\AppData\\Local\\Temp/ipykernel_7120/953631979.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    (parallel_0): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), padding=same)\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9d07fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tmp(nn.Module):\n",
    "    def __init__(self,a):\n",
    "        super(tmp, self).__init__()\n",
    "        self.net=nn.Sequential()\n",
    "        self.net.add_module('dict',nn.ModuleDict(a))\n",
    "    def forward(self,x):\n",
    "#         a=getattr(self, '123123')\n",
    "#         a.add_module('456',nn.Linear(4,2))\n",
    "        out=getattr(self,'net')\n",
    "        out=out.dict['a'](x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "70cb38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "di={'a':nn.Linear(2,4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba2d95f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tmp(\n",
       "  (net): Sequential(\n",
       "    (dict): ModuleDict(\n",
       "      (a): Linear(in_features=2, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=tmp(di)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c5355be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([[0.9408, 0.1332],\n",
    "        [0.9346, 0.5936],\n",
    "        [0.8694, 0.5677],\n",
    "        [0.7411, 0.4294]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9eea21d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7961, -0.4668, -0.4197, -0.1295],\n",
       "        [-0.9792, -0.4800, -0.1581,  0.0325],\n",
       "        [-0.9442, -0.4521, -0.1319,  0.0222],\n",
       "        [-0.8402, -0.3943, -0.1292, -0.0289]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7e8adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class A(nn.Module):\n",
    "    def __init__(self,layers):\n",
    "        super(A, self).__init__()\n",
    "        self.layer=nn.Sequential(nn.Linear(2,4),*layers)\n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aad0c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(B, self).__init__()\n",
    "        self.layer=nn.Linear(4,2)\n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd6df4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(B, self).__init__()\n",
    "        self.layer=nn.Linear(2,1)\n",
    "        self.layer1=nn.Linear(2,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out1 = self.layer1(x)\n",
    "        out = torch.cat([out,out1],dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "291e779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90a56619",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_b=B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4514451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=A([b,b_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b87b632f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f069d515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A(\n",
       "  (layer): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "    (1): B(\n",
       "      (layer): Linear(in_features=4, out_features=2, bias=True)\n",
       "    )\n",
       "    (2): B(\n",
       "      (layer): Linear(in_features=2, out_features=1, bias=True)\n",
       "      (layer1): Linear(in_features=2, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab6a744f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0076,  0.5564],\n",
       "        [-0.0042,  0.5767],\n",
       "        [-0.0118,  0.5817],\n",
       "        [-0.0247,  0.5877]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b43ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

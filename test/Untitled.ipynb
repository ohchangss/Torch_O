{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ae3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import Dataset, TensorDataset,DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d11819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "#         super(self, Model).__init__()\n",
    "        \n",
    "#     dataloader = DataLoader(dataset, batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS)\n",
    "    \n",
    "#     #아직 신경망이 작으므로 한번에 적음\n",
    "#     model = torch.nn.Linear(10,1).to(DEVICE)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE) \n",
    "    \n",
    "#     loss_func=nn.MSELoss()\n",
    "#     loss_arr=[]\n",
    "#     nb_epochs = EPOCH\n",
    "#     for epoch in range(nb_epochs + 1):\n",
    "#         for batch_idx, samples in enumerate(dataloader):\n",
    "\n",
    "#             x_train, y_train = samples\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             # predict\n",
    "#             output = model(x_train)\n",
    "\n",
    "#             loss = loss_func(output, y_train)\n",
    "\n",
    "#             # cost로 H(x) 계산\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "#                 epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "#                 loss.item()\n",
    "#                 ))\n",
    "#             loss_arr.append(loss.cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6079f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set_data(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dc14e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Torch_dataset(Dataset, object):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        \n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X_data.shape[0]\n",
    "    \n",
    "    def __get_item__(self,idx):\n",
    "        x = torch.FloatTensor(self.X_train[idx])\n",
    "        y = torch.FloatTensor(self.y_train[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f52f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abalone_dataset(self):\n",
    "    with open(DATA_DIR) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader, None)\n",
    "        rows = []\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "\n",
    "\n",
    "        input_cnt, output_cnt = 10, 1\n",
    "\n",
    "        data = np.zeros([len(rows), input_cnt+output_cnt])\n",
    "\n",
    "        for n, row in enumerate(rows):\n",
    "            if row[0] == 'I': data[n, 0] = 1\n",
    "            if row[0] == 'M': data[n, 1] = 1\n",
    "            if row[0] == 'F': data[n, 2] = 1\n",
    "            data[n, 3:] = row[1:]\n",
    "\n",
    "        x_data = data[:,:input_cnt]\n",
    "        y_data = data[:,input_cnt:]\n",
    "        \n",
    "        self.shuffle_data(x_data, y_data, 0.8)\n",
    "        \n",
    "        return [X_data, y_data]\n",
    "    \n",
    "Set_data.get_data = abalone_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_test_split(self,X_data, y_data, train_rate=0.8):\n",
    "    data_count = len(xs)\n",
    "\n",
    "    tr_cnt = int(data_count * tr_ratio / 10) * 10\n",
    "    va_cnt = int(data_count * va_ratio)\n",
    "    te_cnt = data_count - (tr_cnt + va_cnt)\n",
    "\n",
    "    tr_from, tr_to = 0, tr_cnt\n",
    "    va_from, va_to = tr_cnt, tr_cnt + va_cnt\n",
    "    te_from, te_to = tr_cnt + va_cnt, data_count\n",
    "\n",
    "    indices = np.arange(data_count)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    self.tr_xs = xs[indices[tr_from:tr_to]]\n",
    "    self.tr_ys = ys[indices[tr_from:tr_to]]\n",
    "    self.va_xs = xs[indices[va_from:va_to]]\n",
    "    self.va_ys = ys[indices[va_from:va_to]]\n",
    "    self.te_xs = xs[indices[te_from:te_to]]\n",
    "    self.te_ys = ys[indices[te_from:te_to]]\n",
    "\n",
    "    self.input_shape = xs[0].shape\n",
    "    self.output_shape = ys[0].shape\n",
    "    \n",
    "    return \n",
    "\n",
    "set_data.Train_test_split = Train_test_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

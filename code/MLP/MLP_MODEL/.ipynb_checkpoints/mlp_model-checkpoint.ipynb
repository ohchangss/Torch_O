{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac18125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8418198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, name, dataset):\n",
    "        self.name = name\n",
    "        self.dataset = dataset\n",
    "        self.is_training = False\n",
    "        if not hasattr(self, 'rand_std'): self.rand_std = 0.030\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}/{}'.format(self.name, self.dataset)\n",
    "\n",
    "    def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,\n",
    "                 report=0, show_cnt=3, num_workers=0):\n",
    "        self.train(epoch_count, batch_size, learning_rate, report, num_workers)\n",
    "        self.test()\n",
    "#         if show_cnt > 0: self.visualize(show_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f90bf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp_Torch(Model):\n",
    "    def __init__(self, name, dataset, hconfigs):\n",
    "        self.layers=[]\n",
    "        super(Mlp_Torch, self).__init__(name, dataset)\n",
    "        self.make_layers(hconfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6eee11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#우선 SLP 하나로 테스트 해보고 그 뒤 추후 늘린다.\n",
    "def mlp_make_layer_torch(self, hconfigs):\n",
    "    self.hconfig = hconfigs\n",
    "    \n",
    "    prev_shape = self.dataset.input_shape\n",
    "    \n",
    "    for hconfig in hconfigs:\n",
    "        #hconfig에는 output값이 들어있음.\n",
    "        _, prev_shape=self.alloc_make_layer(prev_shape, hconfig)\n",
    "        \n",
    "    output_cnt = int(np.prod(self.dataset.output_shape))\n",
    "    self.alloc_make_layer(prev_shape, output_cnt, atf=False)\n",
    "\n",
    "def mlp_alloc_make_layer_torch(self, input_shape, hconfig, atf=True):\n",
    "    \n",
    "    input_cnt = np.prod(input_shape)\n",
    "    output_cnt = np.prod(hconfig)\n",
    "    self.layers.append(nn.Linear(in_features=input_cnt,out_features=output_cnt))\n",
    "    if atf:\n",
    "        self.layers.append(nn.ReLU())\n",
    "        return input_cnt, output_cnt\n",
    "    \n",
    "    \n",
    "Mlp_Torch.make_layers = mlp_make_layer_torch\n",
    "Mlp_Torch.alloc_make_layer = mlp_alloc_make_layer_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9477b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc6b100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_torch(self, epoch_count=10, batch_size=10, \\\n",
    "                    learning_rate=0.001, report=0, num_workers = 0):\n",
    "    \n",
    "    self.learning_rate = learning_rate\n",
    "#     print(batch_size)\n",
    "    time1 = time2 = int(time.time())\n",
    "    \n",
    "    if report != 0:\n",
    "        print('Model {} train started'.format(self.name),'\\n'*2)\n",
    "        \n",
    "    # 이부분에서 dataset.Dataloader에서 train_data를 가져오면 된다. 33434\n",
    "    # -> or enumerate돌아가는 부분에서 dataloader함수를 호출하여 배치 단위별로 불러온다.\n",
    "    \n",
    "    #  어짜피 인스턴스로 가져오는거니깐 for문 밖에서 정의 해주고 불러온다.\n",
    "    # 이부분에서 그럼 self에 저장된 변수를 그냥 가져와서 전역변수로 사용한다.\n",
    "    \n",
    "    train_loader=self.dataset.dataloader(self.dataset.tr_xs, self.dataset.tr_ys, batch_size, num_workers)\n",
    "    model=Net(self.layers)\n",
    "    self.model = model.to(DEVICE)\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=self.learning_rate)\n",
    "    loss_func = nn.MSELoss()\n",
    "    \n",
    "    print('레이어는 아래와 같습니다.\\n\\n',model)\n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        epoch = epoch+1\n",
    "        costs = []\n",
    "        accs = []\n",
    "        print('\\n !!!start!!!! \\n')\n",
    "\n",
    "        for batch_idx, samples in enumerate(train_loader):\n",
    "\n",
    "            X_train, y_train = samples\n",
    "            \n",
    "            X_train=X_train.to(DEVICE)\n",
    "            y_train=y_train.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(X_train)\n",
    "            loss = loss_func(output, y_train)\n",
    "            acc = self.eval_accuracy(X_train,y_train,output)\n",
    "            \n",
    "#             costs.append(loss)\n",
    "            \n",
    "            # cost로 H(x) 계산\n",
    "#             costs.append(loss.cpu().detach().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            costs.append(loss.cpu().detach().numpy())\n",
    "            accs.append(acc.cpu().detach().numpy())\n",
    "            \n",
    "            if report > 0 and (epoch+1) % report == 0:\n",
    "                print('Epoch {:4d}/{} Batch_Data {}/{} Cost: {:.6f} ACC :{:.6f}'.format(\n",
    "                        epoch, epoch_count, batch_size * (batch_idx+1), len(train_loader)*batch_size,\n",
    "                        np.mean(costs), np.mean(accs)\n",
    "                        ))\n",
    "\n",
    "            \n",
    "#             # get_ validate_data => 설정\n",
    "#             vaX, vaY = self.dataset.get_validate_data(100)\n",
    "#             acc = self.eval_accuracy(vaX, vaY)\n",
    "#             time3 = int(time.time())\n",
    "#             tm1, tm2 = time3-time2, time3-time1\n",
    "#             self.dataset.train_prt_result(epoch+1, costs, accs, acc, tm1, tm2)\n",
    "#             time2 = time3\n",
    "            \n",
    "Mlp_Torch.train = train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_eval_accuracy(self, x, y, output):\n",
    "    if output is None :\n",
    "        print('output = None')\n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    return accuracy\n",
    "\n",
    "Mlp_Torch.eval_accuracy = mlp_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c969db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mlp_model_test(self):\n",
    "#     teX, teY = self.dataset.get_test_data()\n",
    "#     time1 = int(time.time())\n",
    "#     acc = self.eval_accuracy(teX, teY)\n",
    "#     time2 = int(time.time())\n",
    "#     self.dataset.test_prt_result(self.name, acc, time2-time1)\n",
    "\n",
    "# MlpModel.test = mlp_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12a4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(self):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        teX = torch.tensor(self.dataset.te_xs).float().to(DEVICE)\n",
    "        teY = torch.tensor(self.dataset.te_ys).float().to(DEVICE)\n",
    "        \n",
    "        output = self.model.forward(teX)\n",
    "        acc = self.eval_accuracy(teX, teY, output)\n",
    "        print('Model {} test report: accuracy = {:5.3f}, (추가secs)\\n'. \\\n",
    "          format(self.name, acc))\n",
    "#         output = self.model.forward(teX)\n",
    "        \n",
    "\n",
    "#         time1 = int(time.time())\n",
    "        \n",
    "#         # 이부분이 이상함. \n",
    "        \n",
    "#         for sample in test_loader:\n",
    "#             X, y = sample\n",
    "#             X_test=X.to(DEVICE)\n",
    "#             y_test = y.to(DEVICE)\n",
    "            \n",
    "#             output = self.model.forward(X_test)\n",
    "#             acc = self.eval_accuracy(teX, teY)\n",
    "#         time2 = int(time.time())\n",
    "#         self.dataset.test_prt_result(self.name, acc, time2-time1)\n",
    "\n",
    "            \n",
    "#     teX, teY = self.dataset.get_test_data()\n",
    "# #     time1 = int(time.time())\n",
    "#     acc = self.eval_accuracy(teX, teY)\n",
    "#     time2 = int(time.time())\n",
    "#     self.dataset.test_prt_result(self.name, acc, time2-time1)\n",
    "\n",
    "Mlp_Torch.test = test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efad862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mlp_eval_accuracy(self, x, y, output=None):\n",
    "def mlp_eval_accuracy_torch(self, x, y, output):\n",
    "#     if output is None:\n",
    "#         output, _ = self.forward_neuralnet(x)\n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    return accuracy\n",
    "\n",
    "Mlp_Torch.eval_accuracy = mlp_eval_accuracy_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_get_estimate_torch(self, x):\n",
    "    output, _ = self.forward_neuralnet(x)\n",
    "    estimate = self.dataset.get_estimate(output)\n",
    "    return estimate\n",
    "\n",
    "Mlp_Torch.get_estimate = mlp_get_estimate_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0228c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

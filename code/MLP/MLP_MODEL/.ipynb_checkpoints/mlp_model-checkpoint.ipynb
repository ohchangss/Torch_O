{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac18125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8418198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, name, dataset, auto_flat=True):\n",
    "        self.name = name\n",
    "        self.dataset = dataset\n",
    "        self.is_training = False\n",
    "        self.auto_flat = auto_flat\n",
    "        \n",
    "        if not hasattr(self, 'rand_std'): self.rand_std = 0.030\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}/{}'.format(self.name, self.dataset)\n",
    "\n",
    "    def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,\n",
    "                 report=0, show_cnt=3, num_workers=0):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "         # make auto fully-> flatten\n",
    "        \n",
    "        self.train(epoch_count, batch_size, learning_rate, report, num_workers)\n",
    "        self.test()\n",
    "        if show_cnt > 0: self.visualize(show_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f90bf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp_Torch(Model):\n",
    "    def __init__(self, name, dataset, hconfigs):\n",
    "        self.layers = [] # add lay\n",
    "        self.use_adam = False\n",
    "        super(Mlp_Torch, self).__init__(name, dataset)\n",
    "        self.init_parameters(hconfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eee11da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8d429df29251>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_parameters_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_layer_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_alloc_make_layer_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_alloc_make_layer_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def mlp_init_parameters_torch(self, hconfigs):\n",
    "    self.hconfig = hconfigs\n",
    "    \n",
    "    prev_shape = self.dataset.input_shape\n",
    "    \n",
    "    for hconfig in hconfigs:\n",
    "        pm, prev_shape=self.alloc_layer_param(prev_shape, hconfig)\n",
    "        self.layers.append(pm)\n",
    "    \n",
    "    output_cnt = int(np.prod(self.dataset.output_shape))\n",
    "    \n",
    "    if self.auto_flat: self.layers.append([nn.Flatten()])\n",
    "        \n",
    "    pm, _ =self.alloc_layer_param(prev_shape, output_cnt)\n",
    "    \n",
    "    self.layers.append(pm) # [[],[],[],[]]\n",
    "    self.layers=sum(self.layers,[]) # [,,,,]\n",
    "def mlp_alloc_make_layer_torch(self, input_shape, hconfig):\n",
    "    pm=[]\n",
    "    input_cnt = np.prod(input_shape)\n",
    "    output_cnt = np.prod(hconfig)\n",
    "    pm.append(nn.Linear(in_features=input_cnt,out_features=output_cnt))\n",
    "#     act=self.activate()\n",
    "    \n",
    "#     if act == 'None':\n",
    "#         pass\n",
    "#     else:\n",
    "#         pm.append(act)\n",
    "        \n",
    "    return pm, output_cnt\n",
    "    \n",
    "def mlp_activate_torch(self):\n",
    "    self.numact = self.numact + 1 \n",
    "    \n",
    "    if self.numact == len(self.hconfig)+1:\n",
    "        return 'None'\n",
    "    else:\n",
    "        return nn.ReLU()\n",
    "    \n",
    "\n",
    "Mlp_Torch.init_parameters = mlp_init_parameters_torch\n",
    "Mlp_Torch.alloc_layer_param = mlp_alloc_make_layer_torch\n",
    "Mlp_Torch.activate = mlp_activate_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9477b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6b100e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/634667319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def train_torch(self, epoch_count=10, batch_size=10, \\\n",
    "                    learning_rate=0.001, report=0, num_workers = 0):    \n",
    "#     global loss_func\n",
    "    self.learning_rate = learning_rate\n",
    "    batch_count = int(self.dataset.train_count / batch_size)\n",
    "    time1 = time2 = int(time.time())\n",
    "    if report != 0:\n",
    "        print('Model {} train started'.format(self.name),'\\n'*2)\n",
    "        \n",
    "    self.model=Net(self.layers).to(DEVICE)\n",
    "#     self.model.apply(self.init_weights) \n",
    "    loss_func = self.get_loss_func(self.dataset.mode)\n",
    "    print(loss_func)\n",
    "    self.optimizer=self.get_optim(self.use_adam)  \n",
    "    self.prtinfo(self.optimizer)\n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        accs1 = []\n",
    "        \n",
    "        self.dataset.shuffle_train_data(batch_size*batch_count)\n",
    "        train_loader=self.dataset.get_train_loader(self.batch_size, self.num_workers, batch_count*batch_size)\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_loader):\n",
    "            X_train, y_train = samples\n",
    "            cost, acc =self.train_step(X_train, y_train, loss_func)\n",
    "            costs.append(cost)\n",
    "            accs.append(acc)\n",
    "            \n",
    "#             costs.append(loss.cpu().detach().numpy())\n",
    "        if report > 0 and (epoch+1) % report == 0:\n",
    "#                 prt_val(batch_size)\n",
    "            va_X, va_Y = self.dataset.get_validate_date(100)\n",
    "    \n",
    "            va_X = torch.from_numpy(va_X).float().to(DEVICE)\n",
    "            va_Y = torch.from_numpy(va_Y).float().to(DEVICE)\n",
    "            \n",
    "            acc = self.eval_accuracy(va_X, va_Y)\n",
    "            time3 = int(time.time())\n",
    "            tm1, tm2 = time3 - time2, time3 - time1\n",
    "            self.dataset.train_prt_result(epoch+1, costs, accs,acc, tm1, tm2)\n",
    "            time2 = time3\n",
    "                \n",
    "    tm_total = int(time.time()) - time1\n",
    "    print('Model {} train ended in {} secs:'.format(self.name, tm_total))\n",
    "\n",
    "            \n",
    "Mlp_Torch.train = train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc40c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_func(self, mode):\n",
    "    if mode == 'regression':\n",
    "        loss_func = nn.MSELoss()\n",
    "    elif mode == 'binary':\n",
    "#         loss_func = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "    elif mode == 'select':\n",
    "#         loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "# nn.\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "    else :\n",
    "        loss_func = None\n",
    "        \n",
    "    assert loss_func is not None, 'loss_func이 None입니다. 다시 확인하세요'\n",
    "    \n",
    "    return loss_func\n",
    "\n",
    "Mlp_Torch.get_loss_func = get_loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb32e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_train_step_torch(self, X_train, y_train, loss_func):\n",
    "    \n",
    "    X_train=X_train.to(DEVICE)\n",
    "    y_train=y_train.to(DEVICE)\n",
    "    \n",
    "    self.optimizer.zero_grad()\n",
    "    output = self.model.forward(X_train)\n",
    "    loss=self.forward_postproc(loss_func, output, y_train)\n",
    "    acc = self.eval_accuracy(X_train, y_train, output)\n",
    "    \n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "Mlp_Torch.train_step = mlp_train_step_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prt_val(self):\n",
    "#     va_X, va_Y = self.dataset.get_validate_date(batch_size)\n",
    "#     acc = self.eval_accuracy(va_X, va_Y)\n",
    "#     time3 = int(time.time())\n",
    "#     tm1, tm2 = time3 - time2, time3 - time1\n",
    "#     self.dataset.train_prt_result(epoch+1, costs, accs, acc, tm1, tm2)\n",
    "#     time2 = time3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_loader(self):\n",
    "#     train_loader=self.dataset.dataloader(self.dataset.tr_xs, self.dataset.tr_ys, self.batch_size, self.num_workers)\n",
    "#     return train_loader\n",
    "\n",
    "# Mlp_Torch.get_train_loader = get_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "differential-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_torch(self, model):\n",
    "    \n",
    "    if isinstance(model, nn.Linear):\n",
    "        torch.nn.init.normal_(model.weight)\n",
    "        torch.nn.init.zeros_(model.bias)\n",
    "    \n",
    "    if isinstance(model, nn.Conv2d):\n",
    "        torch.nn.init.normal_(model.weight)\n",
    "        torch.nn.init.zeros_(model.bias)\n",
    "    \n",
    "#     print('linear, conv2d, weight->normal, bias->zeros did init')\n",
    "Mlp_Torch.init_weights = weights_init_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12a4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(self):\n",
    "    with torch.no_grad():\n",
    "        test_X,test_y=self.dataset.get_test_data()\n",
    "    \n",
    "        test_X=torch.from_numpy(test_X).float().to(DEVICE)\n",
    "        test_y=torch.from_numpy(test_y).float().to(DEVICE)\n",
    "        \n",
    "        time1 = int(time.time())        \n",
    "        acc = self.eval_accuracy(test_X, test_y)\n",
    "        time2 = int(time.time())\n",
    "        self.dataset.test_prt_result(self.name, acc, time2-time1)\n",
    "\n",
    "Mlp_Torch.test = test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efad862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_eval_accuracy_torch(self, x, y, output=None):\n",
    "    if output is None:\n",
    "        with torch.no_grad():\n",
    "            output = self.model.forward(x)\n",
    "            \n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    return accuracy\n",
    "\n",
    "Mlp_Torch.eval_accuracy = mlp_eval_accuracy_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_get_estimate_torch(self, x):\n",
    "    with torch.no_grad():\n",
    "        output = self.model.forward(x)\n",
    "    estimate = self.dataset.get_estimate(output)\n",
    "    return estimate\n",
    "\n",
    "Mlp_Torch.get_estimate = mlp_get_estimate_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_visualize_torch(self, num):\n",
    "    print('Model {} Visualization'.format(self.name))\n",
    "    deX, deY = self.dataset.get_visualize_data(num)\n",
    "    deX = torch.from_numpy(deX).float().to(DEVICE)\n",
    "    deY = torch.from_numpy(deY).float().to(DEVICE)\n",
    "    est = self.get_estimate(deX)\n",
    "    self.dataset.visualize(deX, est, deY)\n",
    "\n",
    "Mlp_Torch.visualize = mlp_model_visualize_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d20d8b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1f7fd7aac785>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n!!!!!!!!!!!!!!!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'!! optimizer !! \\n!!!!!!!!!!!!!!! \\n\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprtinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprt_model_optim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def prt_model_optim(self,optim):\n",
    "    print('!!!!!!!!!!!')    \n",
    "    print('!! Layer !! .\\n!!!!!!!!!!! \\n\\n',self.model)\n",
    "    print('\\n!!!!!!!!!!!!!!!')    \n",
    "    print('!! optimizer !! \\n!!!!!!!!!!!!!!! \\n\\n', optim)\n",
    "Mlp_Torch.prtinfo = prt_model_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(self, use_adam):\n",
    "    \n",
    "    if use_adam:\n",
    "        optim=torch.optim.Adam(self.model.parameters(),lr=self.learning_rate,\\\n",
    "                         betas=(0.9,0.999),eps=1e-08)\n",
    "    else :\n",
    "        optim=torch.optim.SGD(self.model.parameters(),lr = self.learning_rate)\n",
    "    return optim\n",
    "\n",
    "Mlp_Torch.get_optim = get_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "legislative-fusion",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4502758778e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_postproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_postproc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_extra_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_forward_extra_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def forward_postproc(self, loss_func, output, y_train):\n",
    "\n",
    "    loss = self.dataset.forward_postproc(loss_func, output, y_train)\n",
    "#     print(loss)\n",
    "    extra = self.forward_extra_cost()\n",
    "#     return loss + extra\n",
    "    return loss \n",
    "\n",
    "def mlp_forward_extra_cost(self):\n",
    "    return torch.tensor(0).float()\n",
    "\n",
    "\n",
    "Mlp_Torch.forward_postproc = forward_postproc\n",
    "Mlp_Torch.forward_extra_cost = mlp_forward_extra_cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac18125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8418198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, name, dataset):\n",
    "        self.name = name\n",
    "        self.dataset = dataset\n",
    "        self.is_training = False\n",
    "        if not hasattr(self, 'rand_std'): self.rand_std = 0.030\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}/{}'.format(self.name, self.dataset)\n",
    "\n",
    "    def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,\n",
    "                 report=0, show_cnt=3, num_workers=0):\n",
    "        self.train(epoch_count, batch_size, learning_rate, report, num_workers)\n",
    "        self.test()\n",
    "        if show_cnt > 0: self.visualize(show_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f90bf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp_Torch(Model):\n",
    "    def __init__(self, name, dataset, hconfigs):\n",
    "        self.layers = []\n",
    "        self.use_adam = True\n",
    "        self.numact = 0\n",
    "        super(Mlp_Torch, self).__init__(name, dataset)\n",
    "        self.init_parameters(hconfigs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eee11da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8d429df29251>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_parameters_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc_layer_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_alloc_make_layer_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_alloc_make_layer_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def init_parameters_torch(self, hconfigs):\n",
    "    self.hconfig = hconfigs\n",
    "    \n",
    "    prev_shape = self.dataset.input_shape\n",
    "    for hconfig in hconfigs:\n",
    "        pm, prev_shape=self.alloc_layer_param(prev_shape, hconfig)\n",
    "#         print(pm,'pmpmpmpmpmpmpmpmpmpmpmpmpmpmpmpmpmpmpmpm')\n",
    "        self.layers.append(pm)\n",
    "    output_cnt = int(np.prod(self.dataset.output_shape))\n",
    "    self.layers.append([nn.Flatten()])\n",
    "    pm, _ =self.alloc_layer_param(prev_shape, output_cnt)\n",
    "    \n",
    "    self.layers.append(pm)\n",
    "#     print(self.layers)\n",
    "#     print(self.layers,'self.layers')\n",
    "    self.layers=sum(self.layers,[])\n",
    "#     print(self.layers)\n",
    "def mlp_alloc_make_layer_torch(self, input_shape, hconfig):\n",
    "    pm=[]\n",
    "    input_cnt = np.prod(input_shape)\n",
    "    output_cnt = np.prod(hconfig)\n",
    "    pm.append(nn.Linear(in_features=input_cnt,out_features=output_cnt))\n",
    "    act=self.activate()\n",
    "    if act == 'None':\n",
    "        pass\n",
    "    else:\n",
    "        pm.append(act)\n",
    "        \n",
    "    return pm, output_cnt\n",
    "    \n",
    "def mlp_activate_torch(self):\n",
    "    \n",
    "    self.numact = self.numact + 1 \n",
    "    \n",
    "    if self.numact == len(self.hconfig)+1:\n",
    "        return 'None'\n",
    "    else:\n",
    "        return nn.ReLU()\n",
    "    \n",
    "\n",
    "Mlp_Torch.init_parameters = init_parameters_torch\n",
    "Mlp_Torch.alloc_layer_param = mlp_alloc_make_layer_torch\n",
    "Mlp_Torch.activate = mlp_activate_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9477b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6b100e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/634667319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def train_torch(self, epoch_count=10, batch_size=10, \\\n",
    "                    learning_rate=0.001, report=0, num_workers = 0):    \n",
    "    global loss_func\n",
    "        \n",
    "    self.learning_rate = learning_rate\n",
    "    time1 = time2 = int(time.time())\n",
    "    \n",
    "    if report != 0:\n",
    "        print('Model {} train started'.format(self.name),'\\n'*2)\n",
    "    \n",
    "    \n",
    "    train_loader=self.dataset.dataloader(self.dataset.tr_xs, self.dataset.tr_ys, batch_size, num_workers)\n",
    "    \n",
    "    self.model=Net(self.layers).to(DEVICE)\n",
    "#     te_model=self.model\n",
    "    self.model.apply(self.weights_init) \n",
    "    \n",
    "    optimizer=self.get_optim(self.use_adam) \n",
    "    \n",
    "    if self.dataset.mode == 'regression':\n",
    "        loss_func = nn.MSELoss()\n",
    "        \n",
    "    elif self.dataset.mode == 'binary':\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    elif self.dataset.mode == 'select':\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "    else :\n",
    "        loss_func = None\n",
    "    \n",
    "    self.prtinfo(optimizer)\n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        accs1 = []\n",
    "        for batch_idx, samples in enumerate(train_loader):\n",
    "\n",
    "            X_train, y_train = samples\n",
    "            \n",
    "            X_train=X_train.to(DEVICE)\n",
    "            y_train=y_train.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = self.model.forward(X_train)\n",
    "\n",
    "            loss=self.forward_postproc(loss_func, output, y_train)\n",
    "            acc = self.eval_accuracy(X_train, y_train, output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            costs.append(loss.cpu().detach().numpy())\n",
    "            if isinstance(acc, list):\n",
    "                accs.append(acc)\n",
    "            else:\n",
    "                accs.append(acc.cpu().detach().numpy())\n",
    "            \n",
    "\n",
    "\n",
    "            if report > 0 and (batch_idx+1) % report == 0:\n",
    "                va_X, va_Y = self.dataset.get_validate_date(100)\n",
    "                acc = self.eval_accuracy(va_X, va_Y)\n",
    "                time3 = int(time.time())\n",
    "                tm1, tm2 = time3 - time2, time3 - time1\n",
    "                self.dataset.train_prt_result(epoch+1, costs,accs,acc, tm1, tm2)\n",
    "                time2 = time3\n",
    "                \n",
    "    tm_total = int(time.time()) - time1\n",
    "    print('Model {} train ended in {} secs:'.format(self.name, tm_total))\n",
    "\n",
    "            \n",
    "Mlp_Torch.train = train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "differential-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(self,model):\n",
    "    if isinstance(model, nn.Conv2d):\n",
    "        torch.nn.init.normal_(model.weight)\n",
    "        torch.nn.init.zeros_(model.bias)\n",
    "\n",
    "#     self.model.apply(weights_init)\n",
    "\n",
    "Mlp_Torch.weights_init = weights_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12a4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(self):\n",
    "    with torch.no_grad():\n",
    "        print(self.model.parameters)\n",
    "        test_X,test_y=self.dataset.get_test_data()\n",
    "        time1 = int(time.time())        \n",
    "        acc = self.eval_accuracy(test_X, test_y)\n",
    "        time2 = int(time.time())\n",
    "        self.dataset.test_prt_result(self.name, acc, time2-time1)\n",
    "\n",
    "Mlp_Torch.test = test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efad862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_eval_accuracy_torch(self, x, y, output=None):\n",
    "    if output is None:\n",
    "        with torch.no_grad():\n",
    "#             x=x.view([-1,3,96,96])\n",
    "            \n",
    "            output = self.model.forward(x)\n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "Mlp_Torch.eval_accuracy = mlp_eval_accuracy_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_get_estimate_torch(self, x):\n",
    "    with torch.no_grad():\n",
    "#         x=x.view([-1,3,96,96])\n",
    "        output = self.model.forward(x)\n",
    "    estimate = self.dataset.get_estimate(output)\n",
    "    return estimate\n",
    "\n",
    "Mlp_Torch.get_estimate = mlp_get_estimate_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_visualize_torch(self, num):\n",
    "    print('Model {} Visualization'.format(self.name))\n",
    "    deX, deY = self.dataset.get_visualize_data(num)\n",
    "    est = self.get_estimate(deX)\n",
    "    self.dataset.visualize(deX, est, deY)\n",
    "\n",
    "Mlp_Torch.visualize = mlp_model_visualize_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d20d8b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1f7fd7aac785>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n!!!!!!!!!!!!!!!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'!! optimizer !! \\n!!!!!!!!!!!!!!! \\n\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprtinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprt_model_optim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def prt_model_optim(self,optim):\n",
    "    print('!!!!!!!!!!!')    \n",
    "    print('!! Layer !! .\\n!!!!!!!!!!! \\n\\n',self.model)\n",
    "    print('\\n!!!!!!!!!!!!!!!')    \n",
    "    print('!! optimizer !! \\n!!!!!!!!!!!!!!! \\n\\n', optim)\n",
    "Mlp_Torch.prtinfo = prt_model_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(self, use_adam):\n",
    "    \n",
    "    if use_adam:\n",
    "        optim=torch.optim.Adam(self.model.parameters(),lr=self.learning_rate,\\\n",
    "                         betas=(0.9,0.999),eps=1e-08)\n",
    "    \n",
    "    else :\n",
    "        optim=torch.optim.SGD(self.model.parameters(),lr = self.learning_rate)\n",
    "        \n",
    "    \n",
    "    return optim\n",
    "\n",
    "Mlp_Torch.get_optim = get_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "legislative-fusion",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4502758778e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_postproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_postproc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_extra_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_forward_extra_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def forward_postproc(self, loss_func, output, y_train):\n",
    "\n",
    "    loss = self.dataset.forward_postproc(loss_func, output, y_train)\n",
    "    extra = self.forward_extra_cost()\n",
    "    \n",
    "    return loss + extra\n",
    "\n",
    "\n",
    "def mlp_forward_extra_cost(self):\n",
    "    return torch.tensor(0).float()\n",
    "\n",
    "\n",
    "Mlp_Torch.forward_postproc = forward_postproc\n",
    "Mlp_Torch.forward_extra_cost = mlp_forward_extra_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backprop_postproc(self,aux):\n",
    "#     self.loss.backward()\n",
    "    \n",
    "    \n",
    "# Mlp_Torch.backprop_postproc = backprop_postproc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac18125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8418198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, name, dataset):\n",
    "        self.name = name\n",
    "        self.dataset = dataset\n",
    "        self.is_training = False\n",
    "        if not hasattr(self, 'rand_std'): self.rand_std = 0.030\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}/{}'.format(self.name, self.dataset)\n",
    "\n",
    "    def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,\n",
    "                 report=0, show_cnt=3, num_workers=0):\n",
    "        self.train(epoch_count, batch_size, learning_rate, report, num_workers)\n",
    "        self.test()\n",
    "        if show_cnt > 0: self.visualize(show_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f90bf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp_Torch(Model):\n",
    "    def __init__(self, name, dataset, hconfigs):\n",
    "        self.layers=[]\n",
    "        super(Mlp_Torch, self).__init__(name, dataset)\n",
    "        self.make_layers(hconfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6eee11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#우선 SLP 하나로 테스트 해보고 그 뒤 추후 늘린다.\n",
    "def mlp_make_layer_torch(self, hconfigs):\n",
    "    self.hconfig = hconfigs\n",
    "    \n",
    "    prev_shape = self.dataset.input_shape\n",
    "    \n",
    "    for hconfig in hconfigs:\n",
    "        #hconfig에는 output값이 들어있음.\n",
    "        _, prev_shape=self.alloc_make_layer(prev_shape, hconfig)\n",
    "        \n",
    "    output_cnt = int(np.prod(self.dataset.output_shape))\n",
    "    self.alloc_make_layer(prev_shape, output_cnt, atf=False)\n",
    "\n",
    "def mlp_alloc_make_layer_torch(self, input_shape, hconfig, atf=True):\n",
    "    \n",
    "    input_cnt = np.prod(input_shape)\n",
    "    output_cnt = np.prod(hconfig)\n",
    "    self.layers.append(nn.Linear(in_features=input_cnt,out_features=output_cnt))\n",
    "    if atf:self.layers.append(nn.ReLU())\n",
    "#     if atf==False and self.dataset.mode =='select':\n",
    "#         self.layers.append(nn.Softmax(dim=1))\n",
    "    return input_cnt, output_cnt\n",
    "    \n",
    "    \n",
    "Mlp_Torch.make_layers = mlp_make_layer_torch\n",
    "Mlp_Torch.alloc_make_layer = mlp_alloc_make_layer_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9477b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6b100e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mlp_Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/634667319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mMlp_Torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Mlp_Torch' is not defined"
     ]
    }
   ],
   "source": [
    "def train_torch(self, epoch_count=10, batch_size=10, \\\n",
    "                    learning_rate=0.001, report=0, num_workers = 0):\n",
    "    \n",
    "    self.learning_rate = learning_rate\n",
    "    time1 = time2 = int(time.time())\n",
    "    \n",
    "    if report != 0:\n",
    "        print('Model {} train started'.format(self.name),'\\n'*2)\n",
    "    \n",
    "    \n",
    "    train_loader=self.dataset.dataloader(self.dataset.tr_xs, self.dataset.tr_ys, batch_size, num_workers)\n",
    "    self.model=Net(self.layers).to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(self.model.parameters(),lr = self.learning_rate)\n",
    "#     optimizer=torch.optim.Adam(self.model.parameters(),lr=self.learning_rate,betas=(0.9,0.999),eps=1e-08)\n",
    "    if self.dataset.mode == 'regression':\n",
    "        loss_func = nn.MSELoss()\n",
    "        \n",
    "    elif self.dataset.mode == 'binary':\n",
    "        loss_func = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    elif self.dataset.mode == 'select':\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "    print('!!!!!!!!!!!')    \n",
    "    print('!! Layer !! .\\n!!!!!!!!!!! \\n\\n',self.model)\n",
    "    print('\\n!!!!!!!!!!!!!!!')    \n",
    "    print('!! optimizer !! \\n!!!!!!!!!!!!!!! \\n\\n', optimizer)\n",
    "    for epoch in range(epoch_count):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_loader):\n",
    "\n",
    "            X_train, y_train = samples\n",
    "            \n",
    "            X_train=X_train.to(DEVICE)\n",
    "            y_train=y_train.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = self.model.forward(X_train)\n",
    "#             print(output.shape)\n",
    "#             print(y_train.squeeze_().shape)\n",
    "#             print(output,'output')\n",
    "#             print(y_train.squeeze_(),'y_train')\n",
    "            loss = loss_func(output, torch.argmax(y_train,dim=1))\n",
    "            acc = self.eval_accuracy(X_train, y_train, output)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            costs.append(loss.cpu().detach().numpy())\n",
    "            accs.append(acc.cpu().detach().numpy())\n",
    "#             print(output)\n",
    "\n",
    "            if report > 0 and (batch_idx+1) % report == 0:\n",
    "                va_X, va_Y = self.dataset.get_validate_date(100)\n",
    "                acc = self.eval_accuracy(va_X, va_Y)\n",
    "                time3 = int(time.time())\n",
    "                tm1, tm2 = time3 - time2, time3 - time1\n",
    "                self.dataset.train_prt_result(epoch+1, costs,accs,acc, tm1, tm2)\n",
    "                time2 = time3\n",
    "                \n",
    "    tm_total = int(time.time()) - time1\n",
    "    print('Model {} train ended in {} secs:'.format(self.name, tm_total))\n",
    "\n",
    "            \n",
    "Mlp_Torch.train = train_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12a4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(self):\n",
    "    with torch.no_grad():\n",
    "        test_X,test_y=self.dataset.get_test_data()\n",
    "        time1 = int(time.time())        \n",
    "        acc = self.eval_accuracy(test_X, test_y)\n",
    "        time2 = int(time.time())\n",
    "        self.dataset.test_prt_result(self.name, acc, time2-time1)\n",
    "\n",
    "Mlp_Torch.test = test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efad862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_eval_accuracy_torch(self, x, y, output=None):\n",
    "    if output is None:\n",
    "        with torch.no_grad():\n",
    "            output = self.model.forward(x)\n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "Mlp_Torch.eval_accuracy = mlp_eval_accuracy_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_get_estimate_torch(self, x):\n",
    "    with torch.no_grad():\n",
    "        output = self.model.forward(x)\n",
    "    estimate = self.dataset.get_estimate(output)\n",
    "    return estimate\n",
    "\n",
    "Mlp_Torch.get_estimate = mlp_get_estimate_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_visualize_torch(self, num):\n",
    "    print('Model {} Visualization'.format(self.name))\n",
    "    deX, deY = self.dataset.get_visualize_data(num)\n",
    "    est = self.get_estimate(deX)\n",
    "    self.dataset.visualize(deX, est, deY)\n",
    "\n",
    "Mlp_Torch.visualize = mlp_model_visualize_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd4fc3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18616/1558387639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                [1.,0.,0.]])\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1114\u001b[0m     def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n\u001b[0;32m   1115\u001b[0m                  reduce=None, reduction: str = 'mean') -> None:\n\u001b[1;32m-> 1116\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[1;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "# a=torch.tensor([[0.3,0.3,0.4],\n",
    "# [0.4,0.3,0.3]])\n",
    "# b=torch.tensor([[0.,0.,1.],\n",
    "#                [1.,0.,0.]])\n",
    "# print(a.shape, b.shape)\n",
    "# nn.CrossEntropyLoss(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d20d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

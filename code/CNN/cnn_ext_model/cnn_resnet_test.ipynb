{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ea0ed756",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../'*3\n",
    "DATASET_DIR = BASE_DIR+'code/util/dataset/dataset_dummy.ipynb'\n",
    "EXTMODEL_DIR = BASE_DIR + 'code/CNN/cnn_ext_model/ext_model.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9c15d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using PyTorch version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "%run {DATASET_DIR}\n",
    "%run {EXTMODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0ca19878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "imagenet = DummyDataset('imagenet', 'select',[3,224,224],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "41d7ae0b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom vgg_19\n",
      "  serial\n",
      "    custom p24\n",
      "      serial\n",
      "        loop\n",
      "          1: conv, [3, 224, 224]=>[64, 224, 224]pm : 64x3x3x3+64 = 1792\n",
      "          2: conv, [64, 224, 224]=>[64, 224, 224]pm : 64x64x3x3+64 = 36928\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "        3: max, [64, 224, 224]=>[64, 112, 112]\n",
      "MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)]\n",
      "    custom p24\n",
      "      serial\n",
      "        loop\n",
      "          4: conv, [64, 112, 112]=>[128, 112, 112]pm : 128x64x3x3+128 = 73856\n",
      "          5: conv, [128, 112, 112]=>[128, 112, 112]pm : 128x128x3x3+128 = 147584\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "        6: max, [128, 112, 112]=>[128, 56, 56]\n",
      "MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "[Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)]\n",
      "    custom p24\n",
      "      serial\n",
      "        loop\n",
      "          7: conv, [128, 56, 56]=>[256, 56, 56]pm : 256x128x3x3+256 = 295168\n",
      "          8: conv, [256, 56, 56]=>[256, 56, 56]pm : 256x256x3x3+256 = 590080\n",
      "          9: conv, [256, 56, 56]=>[256, 56, 56]pm : 256x256x3x3+256 = 590080\n",
      "          10: conv, [256, 56, 56]=>[256, 56, 56]pm : 256x256x3x3+256 = 590080\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "        11: max, [256, 56, 56]=>[256, 28, 28]\n",
      "MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "[Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)]\n",
      "    custom p24\n",
      "      serial\n",
      "        loop\n",
      "          12: conv, [256, 28, 28]=>[512, 28, 28]pm : 512x256x3x3+512 = 1180160\n",
      "          13: conv, [512, 28, 28]=>[512, 28, 28]pm : 512x512x3x3+512 = 2359808\n",
      "          14: conv, [512, 28, 28]=>[512, 28, 28]pm : 512x512x3x3+512 = 2359808\n",
      "          15: conv, [512, 28, 28]=>[512, 28, 28]pm : 512x512x3x3+512 = 2359808\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "        16: max, [512, 28, 28]=>[512, 14, 14]\n",
      "MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "[Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)]\n",
      "    custom p24\n",
      "      serial\n",
      "        loop\n",
      "          17: conv, [512, 14, 14]=>[512, 14, 14]pm : 512x512x3x3+512 = 2359808\n",
      "          18: conv, [512, 14, 14]=>[512, 14, 14]pm : 512x512x3x3+512 = 2359808\n",
      "          19: conv, [512, 14, 14]=>[512, 14, 14]pm : 512x512x3x3+512 = 2359808\n",
      "          20: conv, [512, 14, 14]=>[512, 14, 14]pm : 512x512x3x3+512 = 2359808\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "ReLU()\n",
      "        21: max, [512, 14, 14]=>[512, 7, 7]\n",
      "MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "[Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)]\n",
      "    loop\n",
      "[Linear(in_features=25088, out_features=4096, bias=True)]\n",
      "      22: full, [512, 7, 7]=>[4096]pm :4096x25088+4096=102764544\n",
      "[Linear(in_features=4096, out_features=4096, bias=True)]\n",
      "      23: full, [4096]=>[4096]pm :4096x4096+4096=16781312\n",
      "Linear(in_features=25088, out_features=4096, bias=True)\n",
      "Linear(in_features=4096, out_features=4096, bias=True)\n",
      "[Linear(in_features=25088, out_features=4096, bias=True), Linear(in_features=4096, out_features=4096, bias=True)]\n",
      "1000\n",
      "[Linear(in_features=4096, out_features=1000, bias=True)]\n",
      "24: full, [4096]=>[1000]pm :1000x4096+1000=4097000\n",
      "Total parameter count : 143667240\n"
     ]
    }
   ],
   "source": [
    "CnnExtModel.set_macro('p24',\n",
    "    ['serial',\n",
    "        ['loop', {'repeat':'#repeat'}, ['conv', {'ksize':3, 'chn':'#chn'}]],\n",
    "        ['max', {'stride':2}]])\n",
    "\n",
    "CnnExtModel.set_macro('vgg_19',\n",
    "    ['serial',\n",
    "        ['custom', {'name':'p24', 'args':{'#repeat':2, '#chn':64}}],\n",
    "        ['custom', {'name':'p24', 'args':{'#repeat':2, '#chn':128}}],\n",
    "        ['custom', {'name':'p24', 'args':{'#repeat':4, '#chn':256}}],\n",
    "        ['custom', {'name':'p24', 'args':{'#repeat':4, '#chn':512}}],\n",
    "        ['custom', {'name':'p24', 'args':{'#repeat':4, '#chn':512}}],\n",
    "        ['loop', {'repeat':2}, ['full', {'width':4096}]]])\n",
    "\n",
    "vgg19 = CnnExtModel('vgg_19', imagenet,\n",
    "        ['custom', {'name':'vgg_19'}], dump_structure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "92aa53d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[P_Block(\n",
       "   (p24_1): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (p24_1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_1_2): ReLU()\n",
       "       (p24_1_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_1_4): ReLU()\n",
       "       (p24_1_5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (p24_2): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (p24_2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_2_2): ReLU()\n",
       "       (p24_2_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_2_4): ReLU()\n",
       "       (p24_2_5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (p24_3): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (p24_3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_3_2): ReLU()\n",
       "       (p24_3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_3_4): ReLU()\n",
       "       (p24_3_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_3_6): ReLU()\n",
       "       (p24_3_7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_3_8): ReLU()\n",
       "       (p24_3_9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (p24_4): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (p24_4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_4_2): ReLU()\n",
       "       (p24_4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_4_4): ReLU()\n",
       "       (p24_4_5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_4_6): ReLU()\n",
       "       (p24_4_7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_4_8): ReLU()\n",
       "       (p24_4_9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (p24_5): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (p24_5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_5_2): ReLU()\n",
       "       (p24_5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_5_4): ReLU()\n",
       "       (p24_5_5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_5_6): ReLU()\n",
       "       (p24_5_7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (p24_5_8): ReLU()\n",
       "       (p24_5_9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (vgg_19_6): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (vgg_19_6_1): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "       (vgg_19_6_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "     )\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a49c096c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom plain_34\n",
      "  serial\n",
      "    1: conv, [3, 224, 224]=>[64, 112, 112]pm : 64x3x7x7+64 = 9472\n",
      "    2: max, [64, 112, 112]=>[64, 56, 56]\n",
      "    loop\n",
      "      3: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "      4: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "      5: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "      6: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "      7: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "      8: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "    custom pn\n",
      "      serial\n",
      "        9: conv, [64, 56, 56]=>[128, 28, 28]pm : 128x64x3x3+128 = 73856\n",
      "        loop\n",
      "          10: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          11: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          12: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          13: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          14: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          15: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          16: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "[]\n",
      "aaaaaa\n",
      "    custom pn\n",
      "      serial\n",
      "        17: conv, [128, 28, 28]=>[256, 14, 14]pm : 256x128x3x3+256 = 295168\n",
      "        loop\n",
      "          18: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          19: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          20: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          21: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          22: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          23: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          24: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          25: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          26: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          27: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          28: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "[]\n",
      "aaaaaa\n",
      "    custom pn\n",
      "      serial\n",
      "        29: conv, [256, 14, 14]=>[512, 7, 7]pm : 512x256x3x3+512 = 1180160\n",
      "        loop\n",
      "          30: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "          31: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "          32: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "          33: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "          34: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "[]\n",
      "aaaaaa\n",
      "    35: avg, [512, 7, 7]=>[512, 1, 1]\n",
      "[AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=(1, 1))]\n",
      "36: full, [512, 1, 1]=>[1000]pm :1000x512+1000=513000\n",
      "Total parameter count : 21616232\n"
     ]
    }
   ],
   "source": [
    "CnnExtModel.set_macro('pn',\n",
    "    ['serial',\n",
    "        ['conv', {'ksize':3, 'stride':2, 'chn':'#n', 'actions':'#act'}],\n",
    "        ['loop', {'repeat':'#cnt1'},\n",
    "                 ['conv', {'ksize':3, 'chn':'#n', 'actions':'#act'}]]])\n",
    "\n",
    "CnnExtModel.set_macro('plain_34',\n",
    "    ['serial',\n",
    "        ['conv', {'ksize':7, 'stride':2, 'chn':64, 'actions':'#act'}],\n",
    "        ['max', {'stride':2}],\n",
    "        ['loop', {'repeat':6}, ['conv', {'ksize':3, 'chn':64, 'actions':'#act'}]],\n",
    "        ['custom', {'name':'pn', 'args':{'#cnt1':7, '#n':128, '#act':'#act'}}],\n",
    "        ['custom', {'name':'pn', 'args':{'#cnt1':11, '#n':256, '#act':'#act'}}],\n",
    "        ['custom', {'name':'pn', 'args':{'#cnt1':5, '#n':512, '#act':'#act'}}],\n",
    "        ['avg', {'stride':7}]])\n",
    "\n",
    "plain_34 = CnnExtModel('plain_34', imagenet,\n",
    "       ['custom', {'name':'plain_34', 'args':{'#act':'LA'}}], dump_structure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2273b64b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[rsd_net(\n",
       "   (rsd1): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "     (1): ReLU()\n",
       "     (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (rsd2): Sequential(\n",
       "     (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (1): ReLU()\n",
       "     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (3): ReLU()\n",
       "     (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (5): ReLU()\n",
       "     (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (7): ReLU()\n",
       "     (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (9): ReLU()\n",
       "     (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (11): ReLU()\n",
       "   )\n",
       " ),\n",
       " rsd_net(\n",
       "   (rsd1): Sequential(\n",
       "     (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (rsd2): Sequential(\n",
       "     (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (1): ReLU()\n",
       "     (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (3): ReLU()\n",
       "     (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (5): ReLU()\n",
       "     (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (7): ReLU()\n",
       "     (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (9): ReLU()\n",
       "     (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (11): ReLU()\n",
       "     (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (13): ReLU()\n",
       "   )\n",
       " ),\n",
       " rsd_net(\n",
       "   (rsd1): Sequential(\n",
       "     (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (rsd2): Sequential(\n",
       "     (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (1): ReLU()\n",
       "     (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (3): ReLU()\n",
       "     (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (5): ReLU()\n",
       "     (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (7): ReLU()\n",
       "     (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (9): ReLU()\n",
       "     (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (11): ReLU()\n",
       "     (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (13): ReLU()\n",
       "     (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (15): ReLU()\n",
       "     (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (17): ReLU()\n",
       "     (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (19): ReLU()\n",
       "     (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (21): ReLU()\n",
       "   )\n",
       " ),\n",
       " rsd_net(\n",
       "   (rsd1): Sequential(\n",
       "     (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (rsd2): Sequential(\n",
       "     (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (1): ReLU()\n",
       "     (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (3): ReLU()\n",
       "     (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (5): ReLU()\n",
       "     (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (7): ReLU()\n",
       "     (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (9): ReLU()\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (plain_34_5): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (plain_34_5_1): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=(1, 1))\n",
       "     )\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_34.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "096426f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom residual_34\n",
      "residual_34 residual_34\n",
      "  serial\n",
      "    1: conv, [3, 224, 224]=>[64, 112, 112]pm : 64x3x7x7+64 = 9472\n",
      "    2: max, [64, 112, 112]=>[64, 56, 56]\n",
      "    custom rfull\n",
      "residual_34 rfull\n",
      "      serial\n",
      "        loop\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                3: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "                4: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                5: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "                6: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                7: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "                8: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "    custom rhalf\n",
      "residual_34 rhalf\n",
      "      serial\n",
      "        custom rh\n",
      "residual_34 rh\n",
      "          add\n",
      "            serial\n",
      "              9: conv, [64, 56, 56]=>[128, 28, 28]pm : 128x64x3x3+128 = 73856\n",
      "              10: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "            11: avg, [64, 56, 56]=>[64, 28, 28]\n",
      "        loop\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                12: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                13: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                14: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                15: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                16: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                17: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "    custom rhalf\n",
      "residual_34 rhalf\n",
      "      serial\n",
      "        custom rh\n",
      "residual_34 rh\n",
      "          add\n",
      "            serial\n",
      "              18: conv, [128, 28, 28]=>[256, 14, 14]pm : 256x128x3x3+256 = 295168\n",
      "              19: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "            20: avg, [128, 28, 28]=>[128, 14, 14]\n",
      "        loop\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                21: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                22: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                23: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                24: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                25: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                26: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                27: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                28: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                29: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                30: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "    custom rhalf\n",
      "residual_34 rhalf\n",
      "      serial\n",
      "        custom rh\n",
      "residual_34 rh\n",
      "          add\n",
      "            serial\n",
      "              31: conv, [256, 14, 14]=>[512, 7, 7]pm : 512x256x3x3+512 = 1180160\n",
      "              32: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "            33: avg, [256, 14, 14]=>[256, 7, 7]\n",
      "        loop\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                34: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "                35: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "          custom rf\n",
      "residual_34 rf\n",
      "            add\n",
      "              serial\n",
      "                36: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "                37: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "    38: avg, [512, 7, 7]=>[512, 1, 1]\n",
      "39: full, [512, 1, 1]=>[1000]pm :1000x512+1000=513000\n",
      "Total parameter count : 21616232\n"
     ]
    }
   ],
   "source": [
    "CnnExtModel.set_macro('rf',\n",
    "    ['add', {'x':True},\n",
    "        ['serial', ['conv', {'ksize':3, 'chn':'#n', 'actions':'#act'}],\n",
    "                   ['conv', {'ksize':3, 'chn':'#n', 'actions':'#act'}]]])\n",
    "\n",
    "CnnExtModel.set_macro('rh',\n",
    "    ['add', {'x':False},\n",
    "        ['serial', ['conv', {'ksize':3, 'stride':2, 'chn':'#n', 'actions':'#act'}],\n",
    "                   ['conv', {'ksize':3, 'chn':'#n', 'actions':'#act'}]],\n",
    "        ['avg', {'stride':2}]])\n",
    "\n",
    "CnnExtModel.set_macro('rfull',\n",
    "    ['serial',\n",
    "        ['loop', {'repeat':'#cnt'},\n",
    "                 ['custom', {'name':'rf', 'args':{'#n':'#n', '#act':'#act'}}]]])\n",
    "\n",
    "CnnExtModel.set_macro('rhalf',\n",
    "    ['serial',\n",
    "        ['custom', {'name':'rh', 'args':{'#n':'#n', '#act':'#act'}}],\n",
    "        ['loop', {'repeat':'#cnt1'},\n",
    "                 ['custom', {'name':'rf', 'args':{'#n':'#n', '#act':'#act'}}]]])\n",
    "\n",
    "CnnExtModel.set_macro('residual_34',\n",
    "    ['serial',\n",
    "        ['conv', {'ksize':7, 'stride':2, 'chn':64, 'actions':'#act'}],\n",
    "        ['max', {'stride':2}],\n",
    "        ['custom', {'name':'rfull', 'args':{'#cnt':3, '#n':64, '#act':'#act'}}],\n",
    "        ['custom', {'name':'rhalf', 'args':{'#cnt1':3, '#n':128, '#act':'#act'}}],\n",
    "        ['custom', {'name':'rhalf', 'args':{'#cnt1':5, '#n':256, '#act':'#act'}}],\n",
    "        ['custom', {'name':'rhalf', 'args':{'#cnt1':2, '#n':512, '#act':'#act'}}],\n",
    "        ['avg', {'stride':7}]])\n",
    "\n",
    "residual_34 = CnnExtModel('residual_34', imagenet,\n",
    "    ['custom', {'name':'residual_34', 'args':{'#act':'LA'}}], dump_structure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d4a112ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[normal(\n",
       "   (layer): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "     (1): ReLU()\n",
       "     (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_1): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_1_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_1_2): ReLU()\n",
       "       (rf_1_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_1_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_2): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_2_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_2_2): ReLU()\n",
       "       (rf_2_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_2_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_3): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_3_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_3_2): ReLU()\n",
       "       (rf_3_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_3_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rh_4): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rh_4_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (rh_4_2): ReLU()\n",
       "       (rh_4_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rh_4_4): ReLU()\n",
       "       (rh_4_5): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_5): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_5_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_5_2): ReLU()\n",
       "       (rf_5_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_5_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_6): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_6_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_6_2): ReLU()\n",
       "       (rf_6_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_6_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_7): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_7_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_7_2): ReLU()\n",
       "       (rf_7_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_7_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rh_8): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rh_8_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (rh_8_2): ReLU()\n",
       "       (rh_8_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rh_8_4): ReLU()\n",
       "       (rh_8_5): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_9): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_9_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_9_2): ReLU()\n",
       "       (rf_9_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_9_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_10): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_10_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_10_2): ReLU()\n",
       "       (rf_10_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_10_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_11): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_11_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_11_2): ReLU()\n",
       "       (rf_11_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_11_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_12): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_12_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_12_2): ReLU()\n",
       "       (rf_12_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_12_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_13): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_13_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_13_2): ReLU()\n",
       "       (rf_13_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_13_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rh_14): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rh_14_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (rh_14_2): ReLU()\n",
       "       (rh_14_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rh_14_4): ReLU()\n",
       "       (rh_14_5): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_15): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_15_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_15_2): ReLU()\n",
       "       (rf_15_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_15_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (rf_16): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (rf_16_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_16_2): ReLU()\n",
       "       (rf_16_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (rf_16_4): ReLU()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (residual_34_17): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (residual_34_17_1): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=(1, 1))\n",
       "     )\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_34.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86c51095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using PyTorch version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "%run {DATASET_DIR}\n",
    "%run {EXTMODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0474b5f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom bottleneck_152\n",
      "  serial\n",
      "    1: conv, [3, 224, 224]=>[64, 112, 112]pm : 64x3x7x7+64 = 9472\n",
      "    2: max, [64, 112, 112]=>[64, 56, 56]\n",
      "    custom bfull\n",
      "      serial\n",
      "        loop\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                3: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x1x1+64 = 4160\n",
      "                4: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "                5: conv, [64, 56, 56]=>[256, 56, 56]pm : 256x64x1x1+256 = 16640\n",
      "[Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                6: conv, [256, 56, 56]=>[64, 56, 56]pm : 64x256x1x1+64 = 16448\n",
      "                7: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "                8: conv, [64, 56, 56]=>[256, 56, 56]pm : 256x64x1x1+256 = 16640\n",
      "[Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                9: conv, [256, 56, 56]=>[64, 56, 56]pm : 64x256x1x1+64 = 16448\n",
      "                10: conv, [64, 56, 56]=>[64, 56, 56]pm : 64x64x3x3+64 = 36928\n",
      "                11: conv, [64, 56, 56]=>[256, 56, 56]pm : 256x64x1x1+256 = 16640\n",
      "[Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "[]\n",
      "aaaaaa\n",
      "    custom bhalf\n",
      "      serial\n",
      "        custom bh\n",
      "          add\n",
      "            serial\n",
      "              12: conv, [256, 56, 56]=>[128, 28, 28]pm : 128x256x1x1+128 = 32896\n",
      "              13: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "              14: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "            15: avg, [256, 56, 56]=>[256, 28, 28]\n",
      "[Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2)), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))]\n",
      "        loop\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                16: conv, [512, 28, 28]=>[128, 28, 28]pm : 128x512x1x1+128 = 65664\n",
      "                17: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                18: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "[Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                19: conv, [512, 28, 28]=>[128, 28, 28]pm : 128x512x1x1+128 = 65664\n",
      "                20: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                21: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "[Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                22: conv, [512, 28, 28]=>[128, 28, 28]pm : 128x512x1x1+128 = 65664\n",
      "                23: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                24: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "[Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                25: conv, [512, 28, 28]=>[128, 28, 28]pm : 128x512x1x1+128 = 65664\n",
      "                26: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                27: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "[Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                28: conv, [512, 28, 28]=>[128, 28, 28]pm : 128x512x1x1+128 = 65664\n",
      "                29: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                30: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "[Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                31: conv, [512, 28, 28]=>[128, 28, 28]pm : 128x512x1x1+128 = 65664\n",
      "                32: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                33: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "[Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                34: conv, [512, 28, 28]=>[128, 28, 28]pm : 128x512x1x1+128 = 65664\n",
      "                35: conv, [128, 28, 28]=>[128, 28, 28]pm : 128x128x3x3+128 = 147584\n",
      "                36: conv, [128, 28, 28]=>[512, 28, 28]pm : 512x128x1x1+512 = 66048\n",
      "[Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "[]\n",
      "aaaaaa\n",
      "    custom bhalf\n",
      "      serial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        custom bh\n",
      "          add\n",
      "            serial\n",
      "              37: conv, [512, 28, 28]=>[256, 14, 14]pm : 256x512x1x1+256 = 131328\n",
      "              38: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "              39: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "            40: avg, [512, 28, 28]=>[512, 14, 14]\n",
      "[Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2)), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))]\n",
      "        loop\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                41: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                42: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                43: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                44: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                45: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                46: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                47: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                48: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                49: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                50: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                51: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                52: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                53: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                54: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                55: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                56: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                57: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                58: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                59: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                60: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                61: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                62: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                63: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                64: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                65: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                66: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                67: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                68: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                69: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                70: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                71: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                72: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                73: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                74: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                75: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                76: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                77: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                78: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                79: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                80: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                81: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                82: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                83: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                84: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                85: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                86: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                87: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                88: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                89: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                90: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                91: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                92: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                93: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                94: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                95: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                96: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                97: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                98: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                99: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                100: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                101: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                102: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                103: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                104: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                105: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                106: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                107: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                108: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                109: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                110: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                111: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                112: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                113: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                114: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                115: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                116: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                117: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                118: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                119: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                120: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                121: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                122: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                123: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                124: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                125: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                126: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                127: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                128: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                129: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                130: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                131: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                132: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                133: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                134: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                135: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                136: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                137: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                138: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                139: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                140: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                141: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                142: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                143: conv, [1024, 14, 14]=>[256, 14, 14]pm : 256x1024x1x1+256 = 262400\n",
      "                144: conv, [256, 14, 14]=>[256, 14, 14]pm : 256x256x3x3+256 = 590080\n",
      "                145: conv, [256, 14, 14]=>[1024, 14, 14]pm : 1024x256x1x1+1024 = 263168\n",
      "[Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "[]\n",
      "aaaaaa\n",
      "    custom bhalf\n",
      "      serial\n",
      "        custom bh\n",
      "          add\n",
      "            serial\n",
      "              146: conv, [1024, 14, 14]=>[512, 7, 7]pm : 512x1024x1x1+512 = 524800\n",
      "              147: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "              148: conv, [512, 7, 7]=>[2048, 7, 7]pm : 2048x512x1x1+2048 = 1050624\n",
      "            149: avg, [1024, 14, 14]=>[1024, 7, 7]\n",
      "[Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2)), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))]\n",
      "        loop\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                150: conv, [2048, 7, 7]=>[512, 7, 7]pm : 512x2048x1x1+512 = 1049088\n",
      "                151: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "                152: conv, [512, 7, 7]=>[2048, 7, 7]pm : 2048x512x1x1+2048 = 1050624\n",
      "[Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "          custom bf\n",
      "            add\n",
      "              serial\n",
      "                153: conv, [2048, 7, 7]=>[512, 7, 7]pm : 512x2048x1x1+512 = 1049088\n",
      "                154: conv, [512, 7, 7]=>[512, 7, 7]pm : 512x512x3x3+512 = 2359808\n",
      "                155: conv, [512, 7, 7]=>[2048, 7, 7]pm : 2048x512x1x1+2048 = 1050624\n",
      "[Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=same), ReLU(), BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)]\n",
      "[]\n",
      "aaaaaa\n",
      "    156: avg, [2048, 7, 7]=>[2048, 1, 1]\n",
      "[AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=(0, 0))]\n",
      "157: full, [2048, 1, 1]=>[1000]pm :1000x2048+1000=2049000\n",
      "Total parameter count : 57344360\n"
     ]
    }
   ],
   "source": [
    "CnnExtModel.set_macro('bf',\n",
    "    ['add', {'x':True},\n",
    "        ['serial',\n",
    "            ['conv', {'ksize':1, 'chn':'#n1', 'actions':'#act'}],\n",
    "            ['conv', {'ksize':3, 'chn':'#n1', 'actions':'#act'}],\n",
    "            ['conv', {'ksize':1, 'chn':'#n4', 'actions':'#act'}]]])\n",
    "\n",
    "CnnExtModel.set_macro('bh',\n",
    "    ['add', {'x':False},\n",
    "        ['serial',\n",
    "            ['conv', {'ksize':1, 'stride':2, 'chn':'#n1', 'actions':'#act'}],\n",
    "            ['conv', {'ksize':3, 'chn':'#n1', 'actions':'#act'}],\n",
    "            ['conv', {'ksize':1, 'chn':'#n4', 'actions':'#act'}]],\n",
    "        ['avg', {'stride':2}]])\n",
    "\n",
    "CnnExtModel.set_macro('bfull',\n",
    "    ['serial',\n",
    "        ['loop', {'repeat':'#cnt'},\n",
    "            ['custom', {'name':'bf', 'args':{'#n1':'#n1', '#n4':'#n4',\n",
    "                '#act':'#act'}}]]])\n",
    "\n",
    "CnnExtModel.set_macro('bhalf',\n",
    "    ['serial',\n",
    "        ['custom', {'name':'bh', 'args':{'#n1':'#n1', '#n4':'#n4',\n",
    "                '#act':'#act'}}],\n",
    "        ['loop', {'repeat':'#cnt1'},\n",
    "            ['custom', {'name':'bf', 'args':{'#n1':'#n1', '#n4':'#n4',\n",
    "                '#act':'#act'}}]]])\n",
    "\n",
    "CnnExtModel.set_macro('bottleneck_152',\n",
    "    ['serial',\n",
    "        ['conv', {'ksize':7, 'stride':2, 'chn':64, 'actions':'#act'}],\n",
    "        ['max', {'ksize':3, 'stride':2}],\n",
    "        ['custom', {'name':'bfull','args':{'#cnt':3,'#n1':64,'#n4':256,'#act':'#act'}}],\n",
    "        ['custom', {'name':'bhalf','args':{'#cnt1':7,'#n1':128,'#n4':512,\n",
    "            '#act':'#act'}}],\n",
    "        ['custom', {'name':'bhalf','args':{'#cnt1':35,'#n1':256,'#n4':1024,\n",
    "            '#act':'#act'}}],\n",
    "        ['custom', {'name':'bhalf','args':{'#cnt1':2,'#n1':512,'#n4':2048,\n",
    "            '#act':'#act'}}],\n",
    "        ['avg', {'stride':7}]])\n",
    "\n",
    "bottleneck_152 = CnnExtModel('bottleneck_152', imagenet,\n",
    "        ['custom', {'name':'bottleneck_152', 'args':{'#act':'LAB'}}],\n",
    "                    dump_structure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45bdd434",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[P_Block(\n",
       "   (bf_1): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_1_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_1_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_1_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_1_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_1_5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_1_6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_2): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_2_1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_2_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_2_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_2_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_2_5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_2_6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_3): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_3_1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_3_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_3_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_3_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_3_5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_3_6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bh_4): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bh_4_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "       (bh_4_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_4_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bh_4_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_4_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bh_4_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_4_7): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_5): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_5_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_5_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_5_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_5_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_5_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_5_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_6): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_6_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_6_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_6_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_6_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_6_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_6_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_7): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_7_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_7_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_7_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_7_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_7_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_7_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_8): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_8_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_8_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_8_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_8_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_8_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_8_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_9): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_9_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_9_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_9_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_9_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_9_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_9_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_10): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_10_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_10_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_10_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_10_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_10_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_10_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_11): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_11_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_11_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_11_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_11_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_11_5): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_11_6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bh_12): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bh_12_1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "       (bh_12_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_12_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bh_12_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_12_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bh_12_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_12_7): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_13): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_13_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_13_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_13_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_13_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_13_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_13_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_14): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_14_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_14_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_14_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_14_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_14_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_14_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_15): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_15_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_15_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_15_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_15_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_15_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_15_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_16): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_16_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_16_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_16_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_16_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_16_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_16_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_17): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_17_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_17_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_17_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_17_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_17_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_17_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_18): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_18_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_18_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_18_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_18_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_18_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_18_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_19): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_19_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_19_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_19_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_19_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_19_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_19_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_20): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_20_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_20_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_20_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_20_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_20_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_20_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_21): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_21_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_21_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_21_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_21_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_21_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_21_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_22): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_22_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_22_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_22_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_22_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_22_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_22_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_23): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_23_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_23_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_23_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_23_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_23_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_23_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_24): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_24_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_24_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_24_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_24_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_24_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_24_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_25): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_25_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_25_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_25_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_25_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_25_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_25_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_26): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_26_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_26_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_26_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_26_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_26_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_26_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_27): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_27_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_27_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_27_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_27_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_27_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_27_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_28): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_28_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_28_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_28_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_28_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_28_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_28_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_29): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_29_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_29_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_29_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_29_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_29_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_29_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_30): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_30_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_30_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_30_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_30_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_30_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_30_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_31): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_31_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_31_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_31_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_31_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_31_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_31_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_32): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_32_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_32_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_32_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_32_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_32_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_32_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_33): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_33_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_33_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_33_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_33_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_33_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_33_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_34): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_34_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_34_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_34_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_34_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_34_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_34_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_35): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_35_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_35_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_35_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_35_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_35_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_35_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_36): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_36_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_36_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_36_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_36_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_36_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_36_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_37): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_37_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_37_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_37_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_37_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_37_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_37_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_38): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_38_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_38_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_38_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_38_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_38_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_38_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_39): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_39_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_39_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_39_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_39_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_39_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_39_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_40): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_40_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_40_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_40_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_40_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_40_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_40_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_41): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_41_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_41_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_41_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_41_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_41_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_41_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_42): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_42_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_42_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_42_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_42_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_42_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_42_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_43): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_43_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_43_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_43_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_43_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_43_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_43_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_44): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_44_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_44_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_44_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_44_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_44_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_44_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_45): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_45_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_45_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_45_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_45_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_45_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_45_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_46): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_46_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_46_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_46_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_46_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_46_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_46_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_47): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_47_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_47_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_47_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_47_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_47_5): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_47_6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bh_48): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bh_48_1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "       (bh_48_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_48_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bh_48_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_48_5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bh_48_6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bh_48_7): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_49): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_49_1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_49_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_49_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_49_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_49_5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_49_6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bf_50): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bf_50_1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_50_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_50_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "       (bf_50_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "       (bf_50_5): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bf_50_6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (bottleneck_152_51): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (bottleneck_152_51_1): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=(0, 0))\n",
       "     )\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_152.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937868c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using PyTorch version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "# F_DATA_DIR = BASE_DIR+ 'code/util/dataset/flower_prepro.ipynb'\n",
    "\n",
    "# %run {F_DATA_DIR}\n",
    "\n",
    "# fd = FlowersDataset([64,64], [3,64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0d9ef1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1\n",
    "BATCH_SIZE=20\n",
    "NUM_WORKERS=0\n",
    "LEARNING_RATE = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f06984ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom plain_flower\n",
      "  serial\n",
      "    1: conv, (3, 64, 64)=>[16, 32, 32]pm : 16x3x7x7+16 = 2368\n",
      "    2: max, [16, 32, 32]=>[16, 16, 16]\n",
      "    loop\n",
      "      3: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "      4: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "      5: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "      6: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "    custom pn\n",
      "      serial\n",
      "        7: conv, [16, 16, 16]=>[32, 8, 8]pm : 32x16x3x3+32 = 4640\n",
      "        loop\n",
      "          8: conv, [32, 8, 8]=>[32, 8, 8]pm : 32x32x3x3+32 = 9248\n",
      "          9: conv, [32, 8, 8]=>[32, 8, 8]pm : 32x32x3x3+32 = 9248\n",
      "          10: conv, [32, 8, 8]=>[32, 8, 8]pm : 32x32x3x3+32 = 9248\n",
      "[]\n",
      "aaaaaa\n",
      "    custom pn\n",
      "      serial\n",
      "        11: conv, [32, 8, 8]=>[64, 4, 4]pm : 64x32x3x3+64 = 18496\n",
      "        loop\n",
      "          12: conv, [64, 4, 4]=>[64, 4, 4]pm : 64x64x3x3+64 = 36928\n",
      "          13: conv, [64, 4, 4]=>[64, 4, 4]pm : 64x64x3x3+64 = 36928\n",
      "          14: conv, [64, 4, 4]=>[64, 4, 4]pm : 64x64x3x3+64 = 36928\n",
      "[]\n",
      "aaaaaa\n",
      "    15: avg, [64, 4, 4]=>[64, 1, 1]\n",
      "[AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=(1, 1))]\n",
      "16: full, [64, 1, 1]=>[5]pm :5x64+5=325\n",
      "Total parameter count : 173637\n",
      "Model plain_flower train started \n",
      "\n",
      "\n",
      "!!!!!!!!!!!\n",
      "!! Layer !! .\n",
      "!!!!!!!!!!! \n",
      "\n",
      " Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): rsd_net(\n",
      "      (rsd1): Sequential(\n",
      "        (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (rsd2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (11): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): rsd_net(\n",
      "      (rsd1): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (rsd2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (8): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): rsd_net(\n",
      "      (rsd1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (rsd2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (8): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (3): P_Block(\n",
      "      (plain_flower_4): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (plain_flower_4_1): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Flatten(start_dim=1, end_dim=-1)\n",
      "    (5): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "!!!!!!!!!!!!!!!\n",
      "!! optimizer !! \n",
      "!!!!!!!!!!!!!!! \n",
      "\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0003\n",
      "    weight_decay: 0\n",
      ")\n",
      "    Epoch 1: cost=1.607, accuracy=0.150/0.200 (2/2 secs)\n",
      "    Epoch 1: cost=1.605, accuracy=0.262/0.240 (2/4 secs)\n",
      "    Epoch 1: cost=1.603, accuracy=0.275/0.230 (1/5 secs)\n",
      "    Epoch 1: cost=1.604, accuracy=0.275/0.180 (2/7 secs)\n",
      "    Epoch 1: cost=1.600, accuracy=0.290/0.280 (2/9 secs)\n",
      "    Epoch 1: cost=1.608, accuracy=0.263/0.270 (2/11 secs)\n",
      "    Epoch 1: cost=1.611, accuracy=0.257/0.210 (2/13 secs)\n",
      "    Epoch 1: cost=1.609, accuracy=0.269/0.300 (2/15 secs)\n",
      "    Epoch 1: cost=1.608, accuracy=0.269/0.290 (2/17 secs)\n",
      "    Epoch 1: cost=1.606, accuracy=0.270/0.310 (1/18 secs)\n",
      "    Epoch 1: cost=1.604, accuracy=0.270/0.320 (1/19 secs)\n",
      "    Epoch 1: cost=1.601, accuracy=0.269/0.320 (3/22 secs)\n",
      "    Epoch 1: cost=1.600, accuracy=0.263/0.340 (2/24 secs)\n",
      "    Epoch 1: cost=1.599, accuracy=0.266/0.350 (2/26 secs)\n",
      "    Epoch 1: cost=1.599, accuracy=0.263/0.320 (1/27 secs)\n",
      "    Epoch 1: cost=1.596, accuracy=0.270/0.350 (1/28 secs)\n",
      "    Epoch 1: cost=1.594, accuracy=0.274/0.340 (2/30 secs)\n",
      "    Epoch 1: cost=1.591, accuracy=0.278/0.310 (1/31 secs)\n",
      "    Epoch 1: cost=1.590, accuracy=0.279/0.450 (2/33 secs)\n",
      "    Epoch 1: cost=1.587, accuracy=0.279/0.370 (1/34 secs)\n",
      "    Epoch 1: cost=1.584, accuracy=0.286/0.400 (1/35 secs)\n",
      "    Epoch 1: cost=1.582, accuracy=0.283/0.310 (2/37 secs)\n",
      "    Epoch 1: cost=1.580, accuracy=0.285/0.290 (1/38 secs)\n",
      "    Epoch 1: cost=1.580, accuracy=0.285/0.280 (1/39 secs)\n",
      "    Epoch 1: cost=1.580, accuracy=0.285/0.340 (2/41 secs)\n",
      "    Epoch 1: cost=1.581, accuracy=0.286/0.330 (1/42 secs)\n",
      "    Epoch 1: cost=1.577, accuracy=0.291/0.300 (2/44 secs)\n",
      "    Epoch 1: cost=1.576, accuracy=0.291/0.330 (1/45 secs)\n",
      "    Epoch 1: cost=1.573, accuracy=0.298/0.270 (2/47 secs)\n",
      "    Epoch 1: cost=1.570, accuracy=0.302/0.300 (1/48 secs)\n",
      "    Epoch 1: cost=1.570, accuracy=0.303/0.310 (1/49 secs)\n",
      "    Epoch 1: cost=1.569, accuracy=0.302/0.410 (2/51 secs)\n",
      "    Epoch 1: cost=1.573, accuracy=0.298/0.330 (1/52 secs)\n",
      "    Epoch 1: cost=1.571, accuracy=0.301/0.320 (1/53 secs)\n",
      "    Epoch 1: cost=1.570, accuracy=0.301/0.310 (2/55 secs)\n",
      "    Epoch 1: cost=1.571, accuracy=0.299/0.280 (1/56 secs)\n",
      "    Epoch 1: cost=1.569, accuracy=0.301/0.270 (1/57 secs)\n",
      "    Epoch 1: cost=1.568, accuracy=0.301/0.280 (2/59 secs)\n",
      "    Epoch 1: cost=1.567, accuracy=0.299/0.270 (1/60 secs)\n",
      "    Epoch 1: cost=1.565, accuracy=0.300/0.330 (2/62 secs)\n",
      "    Epoch 1: cost=1.564, accuracy=0.302/0.330 (1/63 secs)\n",
      "    Epoch 1: cost=1.562, accuracy=0.304/0.330 (1/64 secs)\n",
      "    Epoch 1: cost=1.559, accuracy=0.306/0.350 (2/66 secs)\n",
      "    Epoch 1: cost=1.557, accuracy=0.306/0.340 (1/67 secs)\n",
      "    Epoch 1: cost=1.555, accuracy=0.307/0.350 (1/68 secs)\n",
      "    Epoch 1: cost=1.554, accuracy=0.308/0.450 (2/70 secs)\n",
      "    Epoch 1: cost=1.553, accuracy=0.307/0.340 (1/71 secs)\n",
      "    Epoch 1: cost=1.553, accuracy=0.305/0.360 (2/73 secs)\n",
      "    Epoch 1: cost=1.552, accuracy=0.307/0.330 (1/74 secs)\n",
      "    Epoch 1: cost=1.550, accuracy=0.307/0.290 (1/75 secs)\n",
      "    Epoch 1: cost=1.548, accuracy=0.308/0.320 (2/77 secs)\n",
      "    Epoch 1: cost=1.547, accuracy=0.311/0.320 (1/78 secs)\n",
      "    Epoch 1: cost=1.546, accuracy=0.311/0.320 (1/79 secs)\n",
      "    Epoch 1: cost=1.544, accuracy=0.311/0.390 (2/81 secs)\n",
      "    Epoch 1: cost=1.543, accuracy=0.313/0.390 (1/82 secs)\n",
      "    Epoch 1: cost=1.542, accuracy=0.312/0.370 (2/84 secs)\n",
      "    Epoch 1: cost=1.541, accuracy=0.314/0.340 (1/85 secs)\n",
      "    Epoch 1: cost=1.540, accuracy=0.315/0.430 (1/86 secs)\n",
      "    Epoch 1: cost=1.539, accuracy=0.315/0.380 (2/88 secs)\n",
      "    Epoch 1: cost=1.539, accuracy=0.315/0.350 (1/89 secs)\n",
      "    Epoch 1: cost=1.540, accuracy=0.314/0.390 (1/90 secs)\n",
      "    Epoch 1: cost=1.538, accuracy=0.316/0.390 (2/92 secs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 1: cost=1.538, accuracy=0.316/0.350 (1/93 secs)\n",
      "    Epoch 1: cost=1.536, accuracy=0.317/0.390 (1/94 secs)\n",
      "    Epoch 1: cost=1.534, accuracy=0.320/0.340 (2/96 secs)\n",
      "    Epoch 1: cost=1.533, accuracy=0.323/0.360 (1/97 secs)\n",
      "    Epoch 1: cost=1.533, accuracy=0.322/0.420 (2/99 secs)\n",
      "    Epoch 1: cost=1.533, accuracy=0.322/0.460 (1/100 secs)\n",
      "    Epoch 1: cost=1.531, accuracy=0.325/0.360 (1/101 secs)\n",
      "    Epoch 1: cost=1.530, accuracy=0.325/0.360 (1/102 secs)\n",
      "    Epoch 1: cost=1.529, accuracy=0.326/0.270 (2/104 secs)\n",
      "    Epoch 1: cost=1.527, accuracy=0.327/0.350 (1/105 secs)\n",
      "    Epoch 1: cost=1.527, accuracy=0.328/0.430 (2/107 secs)\n",
      "    Epoch 1: cost=1.525, accuracy=0.330/0.400 (1/108 secs)\n",
      "    Epoch 1: cost=1.526, accuracy=0.329/0.390 (2/110 secs)\n",
      "    Epoch 1: cost=1.525, accuracy=0.330/0.380 (1/111 secs)\n",
      "    Epoch 1: cost=1.524, accuracy=0.331/0.320 (1/112 secs)\n",
      "    Epoch 1: cost=1.524, accuracy=0.330/0.410 (2/114 secs)\n",
      "    Epoch 1: cost=1.524, accuracy=0.330/0.410 (1/115 secs)\n",
      "    Epoch 1: cost=1.525, accuracy=0.329/0.440 (2/117 secs)\n",
      "    Epoch 1: cost=1.524, accuracy=0.329/0.430 (1/118 secs)\n",
      "    Epoch 1: cost=1.523, accuracy=0.330/0.370 (1/119 secs)\n",
      "    Epoch 1: cost=1.524, accuracy=0.328/0.400 (2/121 secs)\n",
      "    Epoch 1: cost=1.523, accuracy=0.329/0.370 (1/122 secs)\n",
      "    Epoch 1: cost=1.523, accuracy=0.331/0.400 (1/123 secs)\n",
      "    Epoch 1: cost=1.522, accuracy=0.331/0.390 (2/125 secs)\n",
      "Model plain_flower train ended in 125 secs:\n",
      "<bound method Module.parameters of Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): rsd_net(\n",
      "      (rsd1): Sequential(\n",
      "        (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (rsd2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (8): ReLU()\n",
      "        (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (11): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): rsd_net(\n",
      "      (rsd1): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (rsd2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (8): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): rsd_net(\n",
      "      (rsd1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (rsd2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (8): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (3): P_Block(\n",
      "      (plain_flower_4): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (plain_flower_4_1): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Flatten(start_dim=1, end_dim=-1)\n",
      "    (5): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")>\n",
      "Model plain_flower test report: accuracy = 0.347, (4 secs)\n",
      "\n",
      "Model plain_flower Visualization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [17,44,18, 7,13] =>  dandelion :  daisy => X\n",
      " [14,16,18,23,28] =>  tulip :  daisy => X\n",
      " [16,17,19,21,27] =>  tulip :  dandelion => X\n"
     ]
    }
   ],
   "source": [
    "CnnExtModel.set_macro('plain_flower',\n",
    "    ['serial',\n",
    "        ['conv', {'ksize':7, 'stride':2, 'chn':16, 'actions':'#act'}],\n",
    "        ['max', {'stride':2}],\n",
    "        ['loop', {'repeat':4}, ['conv', {'ksize':3, 'chn':16, 'actions':'#act'}]],\n",
    "        ['custom', {'name':'pn', 'args':{'#cnt1':3, '#n':32, '#act':'#act'}}],\n",
    "        ['custom', {'name':'pn', 'args':{'#cnt1':3, '#n':64, '#act':'#act'}}],\n",
    "        ['avg', {'stride':4}]])\n",
    "\n",
    "plain_flower = CnnExtModel('plain_flower', fd,\n",
    "        ['custom', {'name':'plain_flower', 'args':{'#act':'LBA'}}],\n",
    "                    dump_structure=True)\n",
    "\n",
    "plain_flower.exec_all(epoch_count=EPOCH, report=2, batch_size =BATCH_SIZE \\\n",
    "           , learning_rate = LEARNING_RATE , num_workers = NUM_WORKERS \\\n",
    "          )\n",
    "# plain_flower.exec_all(epoch_count=1, report=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e4c626c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[rsd_net(\n",
       "   (rsd1): Sequential(\n",
       "     (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (rsd2): Sequential(\n",
       "     (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (5): ReLU()\n",
       "     (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (8): ReLU()\n",
       "     (9): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (11): ReLU()\n",
       "   )\n",
       " ),\n",
       " rsd_net(\n",
       "   (rsd1): Sequential(\n",
       "     (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "   )\n",
       "   (rsd2): Sequential(\n",
       "     (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (5): ReLU()\n",
       "     (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (8): ReLU()\n",
       "   )\n",
       " ),\n",
       " rsd_net(\n",
       "   (rsd1): Sequential(\n",
       "     (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "   )\n",
       "   (rsd2): Sequential(\n",
       "     (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (5): ReLU()\n",
       "     (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "     (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "     (8): ReLU()\n",
       "   )\n",
       " ),\n",
       " P_Block(\n",
       "   (plain_flower_4): Sequential(\n",
       "     (dict): ModuleDict(\n",
       "       (plain_flower_4_1): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=(1, 1))\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Flatten(start_dim=1, end_dim=-1)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_flower.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "38235098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom residual_flower\n",
      "  serial\n",
      "    1: conv, (3, 64, 64)=>[16, 32, 32]pm : 16x3x7x7+16 = 2368\n",
      "    2: max, [16, 32, 32]=>[16, 16, 16]\n",
      "    custom rfull\n",
      "      serial\n",
      "        loop\n",
      "          custom rf\n",
      "            add\n",
      "              serial\n",
      "                3: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "                4: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "          custom rf\n",
      "            add\n",
      "              serial\n",
      "                5: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "                6: conv, [16, 16, 16]=>[16, 16, 16]pm : 16x16x3x3+16 = 2320\n",
      "    custom rhalf\n",
      "      serial\n",
      "        custom rh\n",
      "          add\n",
      "            serial\n",
      "              7: conv, [16, 16, 16]=>[32, 8, 8]pm : 32x16x3x3+32 = 4640\n",
      "              8: conv, [32, 8, 8]=>[32, 8, 8]pm : 32x32x3x3+32 = 9248\n",
      "            9: avg, [16, 16, 16]=>[16, 8, 8]\n",
      "        loop\n",
      "          custom rf\n",
      "            add\n",
      "              serial\n",
      "                10: conv, [32, 8, 8]=>[32, 8, 8]pm : 32x32x3x3+32 = 9248\n",
      "                11: conv, [32, 8, 8]=>[32, 8, 8]pm : 32x32x3x3+32 = 9248\n",
      "    custom rhalf\n",
      "      serial\n",
      "        custom rh\n",
      "          add\n",
      "            serial\n",
      "              12: conv, [32, 8, 8]=>[64, 4, 4]pm : 64x32x3x3+64 = 18496\n",
      "              13: conv, [64, 4, 4]=>[64, 4, 4]pm : 64x64x3x3+64 = 36928\n",
      "            14: avg, [32, 8, 8]=>[32, 4, 4]\n",
      "        loop\n",
      "          custom rf\n",
      "            add\n",
      "              serial\n",
      "                15: conv, [64, 4, 4]=>[64, 4, 4]pm : 64x64x3x3+64 = 36928\n",
      "                16: conv, [64, 4, 4]=>[64, 4, 4]pm : 64x64x3x3+64 = 36928\n",
      "    17: avg, [64, 4, 4]=>[64, 1, 1]\n",
      "18: full, [64, 1, 1]=>[5]pm :5x64+5=325\n",
      "Total parameter count : 173637\n",
      "Model residual_flower train started \n",
      "\n",
      "\n",
      "!!!!!!!!!!!\n",
      "!! Layer !! .\n",
      "!!!!!!!!!!! \n",
      "\n",
      " Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): normal(\n",
      "      (layer): Sequential(\n",
      "        (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): P_Block(\n",
      "      (rf_1): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (rf_1_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_1_2): ReLU()\n",
      "          (rf_1_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rf_1_4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_1_5): ReLU()\n",
      "          (rf_1_6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): P_Block(\n",
      "      (rf_2): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (rf_2_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_2_2): ReLU()\n",
      "          (rf_2_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rf_2_4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_2_5): ReLU()\n",
      "          (rf_2_6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): P_Block(\n",
      "      (rh_3): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (rh_3_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (rh_3_2): ReLU()\n",
      "          (rh_3_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rh_3_4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rh_3_5): ReLU()\n",
      "          (rh_3_6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rh_3_7): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): P_Block(\n",
      "      (rf_4): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (rf_4_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_4_2): ReLU()\n",
      "          (rf_4_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rf_4_4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_4_5): ReLU()\n",
      "          (rf_4_6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): P_Block(\n",
      "      (rh_5): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (rh_5_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (rh_5_2): ReLU()\n",
      "          (rh_5_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rh_5_4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rh_5_5): ReLU()\n",
      "          (rh_5_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rh_5_7): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): P_Block(\n",
      "      (rf_6): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (rf_6_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_6_2): ReLU()\n",
      "          (rf_6_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (rf_6_4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (rf_6_5): ReLU()\n",
      "          (rf_6_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): P_Block(\n",
      "      (residual_flower_7): Sequential(\n",
      "        (dict): ModuleDict(\n",
      "          (residual_flower_7_1): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "!!!!!!!!!!!!!!!\n",
      "!! optimizer !! \n",
      "!!!!!!!!!!!!!!! \n",
      "\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0003\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 16, 3, 3], expected input[20, 96, 16, 16] to have 16 channels, but got 96 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12640/3875023204.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                   dump_structure=True)\n\u001b[0;32m     13\u001b[0m residual_flower.exec_all(epoch_count=EPOCH, report=2, batch_size =BATCH_SIZE \\\n\u001b[1;32m---> 14\u001b[1;33m            \u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNUM_WORKERS\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m           )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12640/927826373.py\u001b[0m in \u001b[0;36mexec_all\u001b[1;34m(self, epoch_count, batch_size, learning_rate, report, show_cnt, show_params, num_workers)\u001b[0m\n\u001b[0;32m      9\u001b[0m                  report=0, show_cnt = 3, show_params=False,num_workers=0):\n\u001b[0;32m     10\u001b[0m         super(CnnRegModel, self).exec_all(epoch_count, batch_size, \n\u001b[1;32m---> 11\u001b[1;33m                                          learning_rate, report, show_cnt, num_workers)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_params\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_param_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12640/4054610662.py\u001b[0m in \u001b[0;36mexec_all\u001b[1;34m(self, epoch_count, batch_size, learning_rate, report, show_cnt, num_workers)\u001b[0m\n\u001b[0;32m     11\u001b[0m     def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,\n\u001b[0;32m     12\u001b[0m                  report=0, show_cnt=3, num_workers=0):\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_cnt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_cnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12640/1716686982.py\u001b[0m in \u001b[0;36mtrain_torch\u001b[1;34m(self, epoch_count, batch_size, learning_rate, report, num_workers)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_postproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12640/3870700289.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12640/2462145449.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdep1_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdep1_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mcat_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12640/2462145449.py\u001b[0m in \u001b[0;36mget_output\u001b[1;34m(self, idx, x, nn)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_method\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nalcoding\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 440\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 16, 3, 3], expected input[20, 96, 16, 16] to have 16 channels, but got 96 channels instead"
     ]
    }
   ],
   "source": [
    "CnnExtModel.set_macro('residual_flower',\n",
    "    ['serial',\n",
    "        ['conv', {'ksize':7, 'stride':2, 'chn':16, 'actions':'#act'}],\n",
    "        ['max', {'stride':2}],\n",
    "        ['custom', {'name':'rfull', 'args':{'#cnt':2, '#n':16, '#act':'#act'}}],\n",
    "        ['custom', {'name':'rhalf', 'args':{'#cnt1':1, '#n':32, '#act':'#act'}}],\n",
    "        ['custom', {'name':'rhalf', 'args':{'#cnt1':1, '#n':64, '#act':'#act'}}],\n",
    "        ['avg', {'stride':4}]])\n",
    "\n",
    "residual_flower = CnnExtModel('residual_flower', fd,\n",
    "      ['custom', {'name':'residual_flower', 'args':{'#act':'LAB'}}],\n",
    "                  dump_structure=True)\n",
    "residual_flower.exec_all(epoch_count=EPOCH, report=2, batch_size =BATCH_SIZE \\\n",
    "           , learning_rate = LEARNING_RATE , num_workers = NUM_WORKERS \\\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9657c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CnnExtModel.set_macro('bottleneck_flower',\n",
    "    ['serial',\n",
    "        ['conv', {'ksize':7, 'stride':2, 'chn':16, 'actions':'#act'}],\n",
    "        ['max', {'ksize':3, 'stride':2}],\n",
    "        ['custom', {'name':'bfull', 'args':{'#cnt':1,'#n1':16,'#n4': 64,\n",
    "            '#act':'#act'}}],\n",
    "        ['custom', {'name':'bhalf', 'args':{'#cnt1':2,'#n1':32,'#n4':128\n",
    "            '#act':'#act'}}],\n",
    "        ['custom', {'name':'bhalf', 'args':{'#cnt1':1,'#n1':64,'#n4':256,\n",
    "            '#act':'#act'}}],\n",
    "        ['avg', {'stride':4}]])\n",
    "\n",
    "bottleneck_flower = CnnExtModel('bottleneck_flower', fd,\n",
    "    ['custom', {'name':'bottleneck_flower', 'args':{'#act':'LAB'}}],\n",
    "        dump_structure=True)\n",
    "bottleneck_flower.exec_all(epoch_count=10, report=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

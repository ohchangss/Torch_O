{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef079aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../'*3\n",
    "DATA_DIR = BASE_DIR+ 'code/util/dataset/dataset.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0464e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoShotDataset(Dataset_torch):\n",
    "    def __init__(self, filenames, timesteps=5, count=50, batch=10):\n",
    "        super(VideoShotDataset, self).__init__('videoshot', 'binary')\n",
    "\n",
    "        video_create_cache(filenames)\n",
    "        \n",
    "        self.frames, self.marks = video_load_cache(filenames)\n",
    "\n",
    "        self.set_timesteps(timesteps)\n",
    "        \n",
    "        \n",
    "    def set_timesteps(self, timesteps):\n",
    "        self.timesteps = timesteps\n",
    "        self.input_shape = [timesteps+1, 3, 90, 120]\n",
    "#         self.input_shape = [timesteps+1, 3,90, 120]\n",
    "        self.output_shape = [timesteps+1, 1]\n",
    "        \n",
    "    @property\n",
    "    def train_count(self):\n",
    "        return 2000\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({}, {} frames, {} shots, {} train_data)'. \\\n",
    "               format(self.name, self.mode, len(self.frames), \\\n",
    "                      np.sum(self.marks), self.train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_create_cache(filenames):\n",
    "    movie_path = BASE_DIR + '../big_data/movie/movie/'\n",
    "    cache_path = BASE_DIR+'../big_data/movie/cache/'\n",
    "    \n",
    "    if not os.path.exists(cache_path): os.mkdir(cache_path)\n",
    "\n",
    "    for filename in filenames:\n",
    "        movie_fname = movie_path + filename\n",
    "        cache_fname = cache_path + filename + '.npy'\n",
    "        \n",
    "        if os.path.exists(cache_fname):\n",
    "            print('{}: cache file is found => use cache'.format(filename))\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(movie_fname):\n",
    "            print('{}: file is not found => ERROR'.format(filename))\n",
    "            assert 0\n",
    "        \n",
    "        print('{}: creating cache file...'.format(filename))\n",
    "        \n",
    "        cap = cv2.VideoCapture(movie_fname)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "\n",
    "        shot_idxs = list(np.sort(np.random.randint(0, frame_count-400, 100)))\n",
    "        thumbs = np.zeros([100,4,90,120,3])\n",
    "#         thumbs = np.zeros([100,4, 3, 90,120])\n",
    "        sn = 0\n",
    "                \n",
    "        for fn in range(frame_count-400):\n",
    "            ret = cap.grab()\n",
    "            if fn == shot_idxs[sn]:\n",
    "                for k in range(4):\n",
    "                    _, frame = cap.retrieve(0)\n",
    "                    cap.grab()\n",
    "                    thumbs[sn, k] = cv2.resize(frame, (120, 90))\n",
    "                sn += 1\n",
    "                if sn >= 100: break\n",
    "                \n",
    "        cap.release()\n",
    "        np.save(cache_fname, thumbs)\n",
    "\n",
    "    print('Creating thumbnail cache is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa04d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_load_cache(filenames):\n",
    "    cache_path = BASE_DIR+'../big_data/movie/cache/'\n",
    "\n",
    "#     buffer = np.zeros([len(filenames), 100, 4, 3, 90, 120])\n",
    "    buffer = np.zeros([len(filenames), 100, 4, 90, 120, 3])\n",
    "\n",
    "    for n, filename in enumerate(filenames):\n",
    "        cache_fname = cache_path + filename + '.npy'\n",
    "        buffer[n] = np.load(cache_fname)\n",
    "        \n",
    "    starts = np.zeros([len(filenames), 100, 4])\n",
    "    starts[:,:,0] = 1.0\n",
    "\n",
    "    frames = buffer.reshape([-1, 90, 120, 3])\n",
    "#     frames = buffer.reshape([-1, 3, 90, 120])\n",
    "    shots = starts.reshape([-1])\n",
    "    \n",
    "    return frames, shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20445041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     tmp_x = []\n",
    "#     tmp_y = []\n",
    "#     for i in range(train_count):\n",
    "#         x,y=self.create_seq(batch_size)\n",
    "#         tmp_x.append(x)\n",
    "#         tmp_y.append(y)\n",
    "#     tmp_x=np.array(tmp_x).transpose(0,1,2,5,3,4)\n",
    "#     tmp_y=np.array(tmp_y)\n",
    "#     return tmp_x, tmp_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d96de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_shot_get_train_data(self, batch_size):\n",
    "    return self.create_seq(batch_size)\n",
    "\n",
    "def video_shot_get_test_data(self,count):\n",
    "    return self.create_seq(128)\n",
    "\n",
    "def video_shot_get_validate_data(self, count):\n",
    "    return self.create_seq(count)\n",
    "\n",
    "VideoShotDataset.get_train_data = video_shot_get_train_data\n",
    "VideoShotDataset.get_test_data = video_shot_get_test_data\n",
    "VideoShotDataset.get_validate_data = video_shot_get_validate_data\n",
    "VideoShotDataset.get_visualize_data = video_shot_get_validate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_create_seq(self, count):\n",
    "    length = self.timesteps\n",
    "    xs = np.zeros([count, length+1, 90, 120, 3])\n",
    "    ys = np.zeros([count, length+1, 1])\n",
    "    frame_count = len(self.frames)\n",
    "    for n in range(count):\n",
    "        xs[n, 0, 0, 0, 0] = length\n",
    "        ys[n, 0, 0] = length\n",
    "        pos = frame_count\n",
    "        for k in range(length):\n",
    "            if pos >= frame_count-1 or np.random.randint(2) == 0:\n",
    "                pos = np.random.randint(frame_count)\n",
    "                is_new = 1.0\n",
    "            else:\n",
    "                pos += 1\n",
    "                is_new = self.marks[pos]\n",
    "            xs[n, k+1, :, :, :] = self.frames[pos,:,:,:]\n",
    "            ys[n, k+1, 0] = is_new\n",
    "    return xs, ys\n",
    "\n",
    "VideoShotDataset.create_seq = video_create_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_visualize(self, xs, est, ans):\n",
    "    for n in range(len(xs)):\n",
    "        draw_images_horz(xs[n][1:], [90,120,3])\n",
    "#         draw_images_horz(xs[n][1:], [90,120,3])\n",
    "\n",
    "    for n in range(len(xs)):\n",
    "        print('Est: ' + ','.join([\"%4.2f\" % x for x in est[n,2:,0]]))\n",
    "        print('Ans: ' + ','.join([\"%4.2f\" % x for x in ans[n,2:,0]]))\n",
    "\n",
    "VideoShotDataset.visualize = video_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_shot_forward_postproc(self, loss_func, output, y_train, mode=None):\n",
    "    output, y_train=output[:,2:,:], y_train[:,2:,:]\n",
    "    if mode == None : mode = self.mode\n",
    "\n",
    "    if mode == 'regression':\n",
    "        loss = loss_func(output, y_train)\n",
    "        \n",
    "    elif mode == 'binary':\n",
    "        loss = loss_func(output, y_train)\n",
    "    \n",
    "    elif mode == 'select':\n",
    "        loss = loss_func(output, torch.argmax(y_train,dim=1))\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "VideoShotDataset.forward_postproc = video_shot_forward_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_shot_eval_accuracy(self, x, y, output, mode=None):\n",
    "    y1, o1 = y[:,2:,:], output[:,2:,:]\n",
    "    answer = torch.eq(y1, torch.tensor(1.0))\n",
    "    estimate = torch.greater(o1, 0)\n",
    "    correct = torch.sum(torch.eq(estimate, answer))\n",
    "    accuracy = correct / torch.prod(torch.tensor(y1.shape))\n",
    "                             \n",
    "    return accuracy\n",
    "\n",
    "def video_shot_get_estimate(self, output, mode=None):\n",
    "    estimate = torch.zeros(output.shape)\n",
    "    estimate[:,0,:] = output[:,0,:]\n",
    "    estimate[:,2:,:] = sigmoid(output[:,2:,:])\n",
    "        \n",
    "    return estimate\n",
    "\n",
    "VideoShotDataset.eval_accuracy = video_shot_eval_accuracy\n",
    "VideoShotDataset.get_estimate = video_shot_get_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a266b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for epoch in range(epoch_count):\n",
    "#         costs = []\n",
    "#         accs = []\n",
    "#         self.dataset.shuffle_train_data(batch_size*batch_count)\n",
    "#         for n in range(batch_count):\n",
    "#             trX, trY = self.dataset.get_train_data(batch_size, n)\n",
    "#             cost, acc = self.train_step(trX, trY)\n",
    "#             costs.append(cost)\n",
    "#             accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33db3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_2_torch(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "#         x = x.reshape(-1,)\n",
    "        \n",
    "        self.X_data  = torch.from_numpy(x).float()\n",
    "        self.y_data = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X_data.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        x_ = self.X_data[idx]\n",
    "        y_ = self.y_data[idx]\n",
    "\n",
    "        return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500cd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_torch(self, batch, num):\n",
    "    \n",
    "    self.trX, self.trY = self.get_train_data(batch)\n",
    "    Ds=Dataset_2_torch(self.trX,self.trY)\n",
    "    dataloader = DataLoader(Ds, batch_size=batch, \\\n",
    "                            shuffle=True,num_workers=num)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "VideoShotDataset.dataloader = dataloader_torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bee99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loader(self,batch,num):\n",
    "    train_loader = self.dataloader(batch,num)\n",
    "    return train_loader\n",
    "\n",
    "VideoShotDataset.get_train_loader = get_train_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
